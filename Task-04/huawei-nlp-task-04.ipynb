{"cells":[{"cell_type":"markdown","metadata":{"id":"q8nT8h0S7XWC"},"source":["# 自然语言处理应用\n","\n","[![查看源文件](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source.png)](https://gitee.com/mindspore/docs/blob/master/docs/notebook/mindspore_nlp_application.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"gPjKyWkd7XWD"},"source":["## Обзор\n","\n","Классификация тональности представляет собой подмножество задач классификации текста при обработке естественного языка и относится к наиболее базовым приложениям обработки естественного языка. Это процесс анализа и рассуждения об эмоционально субъективных текстах, то есть анализ отношения говорящего, будь оно положительным или отрицательным.\n","\n","> Обычно мы делим категории эмоций на положительные, отрицательные и нейтральные. Хоть и много «безликих» комментариев, но чаще всего для обучения используются только положительные и отрицательные кейсы, и следующий набор данных является хорошим примером.\n","\n","Типичным справочным набором данных для традиционной задачи классификации текстовых тем является [20 групп новостей] (http://qwone.com/~jason/20Newsgroups/), который состоит из 20 групп новостных данных и содержит около 20 000 новостных документов.\n","Некоторые категории данных в тематическом списке относительно схожи, например, comp.sys.ibm.pc.hardware и comp.sys.mac.hardware — это темы, связанные с аппаратным обеспечением компьютерных систем, и их сходство относительно велико. Некоторые тематические категории имеют относительно несвязанные данные, такие как misc.forsale и soc.religion.christian.\n","\n","Что касается самой сети, то сетевая структура классификации текстовых тем примерно аналогична структуре классификации настроений. После того, как вы освоите построение сети классификации настроений, легко построить аналогичную сеть, которую можно использовать для задач классификации текстовых тем с небольшой настройкой параметров.\n","\n","Но с точки зрения бизнес-контекста классификация тем текста предназначена для анализа объективного содержания текстовых обсуждений, в то время как классификация настроений предназначена для получения информации из текста о том, поддерживает ли он определенную точку зрения. Например, «Форрест Гамп» действительно красив, тема фильма ясна, ритм плавный». и классификация эмоций должна быть раскопана, является ли этот отзыв положительным или отрицательным.\n","\n","По сравнению с традиционной классификацией текстовых тем, классификация настроений проще и практичнее. Обычные веб-сайты для покупок и веб-сайты с фильмами могут собирать наборы данных относительно высокого качества, которые могут легко принести пользу бизнес-сфере. Например, он может автоматически анализировать мнения конкретных типов клиентов о текущем продукте в сочетании с контекстом домена, а также анализировать настроения по темам и типам пользователей для целевой обработки и даже дополнительно рекомендовать продукты на основе этого, улучшая конверсию. скорость, и принести больше выгоды высокая прибыль бизнеса.\n","\n","В специальных полях некоторые неполярные слова также полностью выражают эмоциональные тенденции пользователя, например, при загрузке и использовании приложения «зависание» и «загрузка слишком медленная» выражают негативные эмоциональные тенденции пользователей; \" и \"бычий рынок\" выражают положительные эмоциональные тенденции пользователей. Итак, по сути, мы надеемся, что модель сможет откопать некоторые специальные выражения в вертикальном поле и использовать их в качестве полярных слов для системы классификации настроений:\n","\n","$вертикальное полярное слово = общее полярное слово + полярное слово для предметной области$\n","\n","В зависимости от детализации обработки текста анализ тональности можно разделить на несколько уровней исследования, таких как уровень слова, уровень фразы, уровень предложения, уровень абзаца и уровень главы. Взяв здесь в качестве примера «уровень абзаца», входные данные — это абзацы, а выходные данные — это информация о том, является ли обзор фильма положительным или отрицательным.\n","\n","Затем в качестве примера возьмем классификацию настроений обзоров фильмов IMDB, чтобы испытать применение MindSpore в обработке естественного языка."]},{"cell_type":"markdown","metadata":{"id":"B1R1JNDY7XWE"},"source":["## Общий процесс\n","\n","1. Подготовка.\n","2. Загрузите набор данных и выполните обработку данных.\n","3. Определите сеть.\n","4. Определите оптимизатор и функцию потерь.\n","5. Используйте данные обучения сети для создания модели.\n","6. После получения модели используйте проверочный набор данных, чтобы проверить точность модели.\n","\n","> Этот процесс взаимодействия поддерживает среду CPU или GPU, но среда Ascend в настоящее время не поддерживается."]},{"cell_type":"markdown","metadata":{"id":"5USMNlb17XWE"},"source":["## Подготовка\n","\n","### Скачать набор данных\n","\n","Этот опыт использует набор данных обзора фильмов IMDB в качестве экспериментальных данных.\n","\n","1. Загрузите набор данных обзора фильмов IMDB.\n","\n","     Ниже приведены примеры отрицательных и положительных отзывов.\n","\n","    | Review  | Label  |\n","    |:---|:---:|\n","    | \"Quitting\" may be as much about exiting a pre-ordained identity as about drug withdrawal. As a rural guy coming to Beijing, class and success must have struck this young artist face on as an appeal to separate from his roots and far surpass his peasant parents' acting success. Troubles arise, however, when the new man is too new, when it demands too big a departure from family, history, nature, and personal identity. The ensuing splits, and confusion between the imaginary and the real and the dissonance between the ordinary and the heroic are the stuff of a gut check on the one hand or a complete escape from self on the other.  |  Negative |  \n","    | This movie is amazing because the fact that the real people portray themselves and their real life experience and do such a good job it's like they're almost living the past over again. Jia Hongsheng plays himself an actor who quit everything except music and drugs struggling with depression and searching for the meaning of life while being angry at everyone especially the people who care for him most.  | Positive  |\n","\n","    将下载好的数据集解压并放在当前工作目录下的`datasets`目录下，由于数据集文件较多，解压过程耗时大约15分钟。以下示例代码将数据集下载并解压到指定位置。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":764},"executionInfo":{"elapsed":32317,"status":"ok","timestamp":1653913629823,"user":{"displayName":"Тимур Александрович Гарипов","userId":"06496796590508823817"},"user_tz":-420},"id":"YlfM0T2O7XWF","outputId":"0edcacd6-8d55-450e-9309-f34fd2ad31a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mindspore==1.5\n","  Downloading mindspore-1.5.0-cp37-cp37m-manylinux1_x86_64.whl (77.0 MB)\n","\u001b[K     |████████████████████████████████| 77.0 MB 17 kB/s \n","\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from mindspore==1.5) (7.1.2)\n","Requirement already satisfied: protobuf>=3.13.0 in /usr/local/lib/python3.7/dist-packages (from mindspore==1.5) (3.17.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from mindspore==1.5) (21.3)\n","Collecting asttokens>=1.1.13\n","  Downloading asttokens-2.0.5-py2.py3-none-any.whl (20 kB)\n","Collecting psutil>=5.6.1\n","  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n","\u001b[K     |████████████████████████████████| 281 kB 39.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from mindspore==1.5) (1.21.6)\n","Collecting scipy>=1.5.2\n","  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n","\u001b[K     |████████████████████████████████| 38.1 MB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens>=1.1.13->mindspore==1.5) (1.15.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->mindspore==1.5) (3.0.9)\n","Installing collected packages: scipy, psutil, asttokens, mindspore\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","  Attempting uninstall: psutil\n","    Found existing installation: psutil 5.4.8\n","    Uninstalling psutil-5.4.8:\n","      Successfully uninstalled psutil-5.4.8\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed asttokens-2.0.5 mindspore-1.5.0 psutil-5.9.1 scipy-1.7.3\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["psutil"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (6.0.0)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n"]}],"source":["!pip install mindspore==1.5\n","!pip install tqdm\n","!pip install gensim"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DCnJiL2x7XWG"},"outputs":[],"source":["from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xjbwfN1m7XWG"},"outputs":[],"source":["import os\n","import requests\n","import tarfile\n","import zipfile\n","\n","requests.packages.urllib3.disable_warnings()\n","from tqdm import tqdm\n","\n","def download_dataset(url, target_path):\n","    \"\"\"下载并解压数据集\"\"\"\n","    if not os.path.exists(target_path):\n","        os.makedirs(target_path)\n","    download_file = url.split(\"/\")[-1]\n","    if not os.path.exists(download_file):\n","        res = requests.get(url, stream=True, verify=False)\n","        if download_file.split(\".\")[-1] not in [\"tgz\", \"zip\", \"tar\", \"gz\"]:\n","            download_file = os.path.join(target_path, download_file)\n","        with open(download_file, \"wb\") as f:\n","            for chunk in tqdm(res.iter_content(chunk_size=512)):\n","                if chunk:\n","                    f.write(chunk)\n","    if download_file.endswith(\"zip\"):\n","        z = zipfile.ZipFile(download_file, \"r\")\n","        z.extractall(path=target_path)\n","        z.close()\n","    if download_file.endswith(\".tar.gz\") or download_file.endswith(\".tar\") or download_file.endswith(\".tgz\"):\n","        with tarfile.open(download_file) as t:\n","            names = t.getnames()\n","            for name in tqdm(names):\n","                t.extract(name, target_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":559708,"status":"ok","timestamp":1653914189525,"user":{"displayName":"Тимур Александрович Гарипов","userId":"06496796590508823817"},"user_tz":-420},"id":"ldmMDaBR7XWG","outputId":"386faf53-b211-497d-af71-ca1fd1172668"},"outputs":[{"name":"stderr","output_type":"stream","text":["164309it [00:09, 17480.33it/s]\n","100%|██████████| 100019/100019 [08:57<00:00, 186.05it/s]\n"]}],"source":["download_dataset(\"https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/aclImdb_v1.tar.gz\", \"./datasets\")"]},{"cell_type":"markdown","metadata":{"id":"yXI-EGa_7XWG"},"source":["2. Загрузите файл GloVe.\n","     Загрузите и разархивируйте файлы GloVe в каталог `datasets` в текущем рабочем каталоге и добавьте новую строку, как показано ниже, в начале всех файлов GloVe, что означает, что всего читается 400 000 слов, и каждое слово использует 300-мерный словесный векторный экспресс.\n","\n","     ````\n","     400000 300\n","     ````"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":121342,"status":"ok","timestamp":1653914310861,"user":{"displayName":"Тимур Александрович Гарипов","userId":"06496796590508823817"},"user_tz":-420},"id":"3aFHUvi07XWG","outputId":"4fd27581-8e9d-4d4f-e619-176e451cbdc6"},"outputs":[{"name":"stderr","output_type":"stream","text":["1683951it [01:13, 23010.12it/s]\n","100%|██████████| 4/4 [00:24<00:00,  6.08s/it]\n"]},{"data":{"text/plain":["[None, None, None, None]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["def add_first_line(file, line):\n","    with open(file, \"r+\") as f:\n","        data = f.read()\n","        f.seek(0, 0)\n","        f.write(line+data)\n","\n","download_dataset(\"https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/glove.6B.zip\", \"./datasets/glove\")\n","os.makedirs(\"./preprocess\", exist_ok=True)\n","os.makedirs(\"./ckpt\", exist_ok=True)\n","glove_f = [os.path.join(\"./datasets/glove\", i) for i in os.listdir(\"./datasets/glove\")]\n","[add_first_line(i, \"400000 300\\n\") for i in tqdm(glove_f)]"]},{"cell_type":"markdown","metadata":{"id":"7EDOQkxk7XWG"},"source":["3. Создайте пустой каталог с именем `preprocess` в текущем рабочем каталоге, который будет использоваться для хранения файлов, преобразованных из набора данных IMDB в формат MindRecord в операции предварительной обработки набора данных. Текущая структура рабочего каталога выглядит следующим образом.\n","    ```text\n","    .\n","    ├── aclImdb_v1.tar.gz\n","    ├── ckpt\n","    ├── datasets\n","    │   ├── aclImdb\n","    │   │   ├── imdbEr.txt\n","    │   │   ├── imdb.vocab\n","    │   │   ├── README\n","    │   │   ├── test\n","    │   │   └── train\n","    │   └── glove\n","    │       ├── glove.6B.100d.txt\n","    │       ├── glove.6B.200d.txt\n","    │       ├── glove.6B.300d.txt\n","    │       └── glove.6B.50d.txt\n","    ├── glove.6B.zip\n","    ├── nlp_application.ipynb\n","    └── preprocess\n","    ```"]},{"cell_type":"markdown","source":["![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZIAAAEUCAIAAACOCSdoAAAMb2lDQ1BJQ0MgUHJvZmlsZQAASImVVwdYU8kWnluSkJDQAghICb0JIjWAlBBaAOlFsBGSQEKJMSGo2NFFBdeKiGBFV0UU2wqIDbEri2LviwUVZV3UxYbKm5CArvvK9+b75s5/z5z5T7kz994DgOYHrkSSi2oBkCfOl8aHBTHGpqYxSE8BAWAAACaw5/JkElZsbBS8A4Pj39u7GwBRjFedFFz/nP+vTYcvkPEAQMZDnMGX8fIgbgYAX8eTSPMBICrkllPzJQo8F2JdKXQQ4jIFzlLiHQqcocRHBnQS49kQXwZAjcrlSrMA0LgH5YwCXhbk0fgMsYuYLxIDoDkCYn+ekMuHWOH7iLy8yQpcAbEd1JdA3KzIRMZ3nFl/488Y4udys4awMq6BphYskklyudP/z9T875aXKx+0YQM7VSgNj1fED3N4K2dypAJTIe4WZ0THKHIN8QcRX5l3AFCKUB6epNRHjXkyNswf0IfYhc8NjoTYGOJQcW50lEqekSkK5UAMdws6TZTPSYTYAOJFAllIgkpnk3RyvMoWWp8pZbNU8nNc6YBdha0H8pwklor/jVDAUfFjGoXCxBSIKRBbFYiSoyHWgNhZlpMQqdIZXShkRw/qSOXxCv+tII4XiMOClPxYQaY0NF6lX5InG4wX2yQUcaJVeH++MDFcmR/sFI874D+MBbssELOSBnkEsrFRg7HwBcEhytix5wJxUoKK54MkPyheuRanSHJjVfq4hSA3TCG3gNhdVpCgWosn58PNqeTHMyX5sYlKP/HCbG5ErNIffDmIAmwQDBhADnsGmAyygaitu6Eb3ilnQgEXSEEWEAAnlWRwRcrAjBheE0Ah+AMiAZANrQsamBWAAij/MiRVXp1A5sBswcCKHPAU4jwQCXLhvXxglXjIWjJ4AiWif1jnws6D/ubCrpj/9/JB6TcJC0qiVBL5oEWG5qAmMYQYTAwnhhLtcSPcH/fFo+A1EHZXnIl7D8bxTZ/wlNBOeES4Tugg3J4kKpL+4OUY0AH5Q1W5yPg+F7gN5PTAg3A/yA6ZcX3cCDjh7tAOCw+Alj2glK3yW5EVxg/cf4vgu6eh0iO7kFHyMHIg2e7HlRoOGh5DLIpcf58fpa8ZQ/lmD838aJ/9Xfb5cIz8URNbhB3AzmInsPPYEawBMLDjWCPWih1V4KHd9WRgdw1aix/wJwfyiP5hj6uyqcikzKXWpcvls3IuXzAtX3Hw2JMl06WiLGE+gwW/DgIGR8xzHsFwdXF1BUDxrVG+vt7GDXxDEP3Wb7L5vwPgd7y/v//wN1nEcQD2ecHjf+ibzI4JgLY6AOcO8eTSAqUMV1wI8C2hCU+aITAFlsAOxuMKPIEvCAQhIALEgESQCibCLAvhPpeCqWAmmAeKQSlYDlaDSrARbAE7wG6wHzSAI+AEOAMugsvgOrgLd08neAl6wDvQhyAICaEhdMQQMUOsEUfEFWEi/kgIEoXEI6lIOpKFiBE5MhOZj5QiK5FKZDNSg+xDDiEnkPNIO3IbeYh0IW+QTyiGUlFd1AS1QUeiTJSFRqKJ6AQ0C52CFqIL0KVoBVqN7kLr0RPoRfQ62oG+RHsxgKlj+pg55oQxMTYWg6VhmZgUm42VYOVYNVaHNcHnfBXrwLqxjzgRp+MM3Anu4HA8CefhU/DZ+BK8Et+B1+On8Kv4Q7wH/0qgEYwJjgQfAocwlpBFmEooJpQTthEOEk7Ds9RJeEckEvWJtkQveBZTidnEGcQlxPXEPcRmYjvxMbGXRCIZkhxJfqQYEpeUTyomrSXtIh0nXSF1kj6oqauZqbmqhaqlqYnVitTK1XaqHVO7ovZMrY+sRbYm+5BjyHzydPIy8lZyE/kSuZPcR9Gm2FL8KImUbMo8SgWljnKaco/yVl1d3ULdWz1OXaQ+V71Cfa/6OfWH6h+pOlQHKps6niqnLqVupzZTb1Pf0mg0G1ogLY2WT1tKq6GdpD2gfdCgazhrcDT4GnM0qjTqNa5ovNIka1prsjQnahZqlmse0Lyk2a1F1rLRYmtxtWZrVWkd0rqp1atN1x6lHaOdp71Ee6f2ee3nOiQdG50QHb7OAp0tOid1HtMxuiWdTefR59O30k/TO3WJura6HN1s3VLd3bptuj16Onruesl60/Sq9I7qdehj+jb6HP1c/WX6+/Vv6H8aZjKMNUwwbPGwumFXhr03GG4QaCAwKDHYY3Dd4JMhwzDEMMdwhWGD4X0j3MjBKM5oqtEGo9NG3cN1h/sO5w0vGb5/+B1j1NjBON54hvEW41bjXhNTkzATiclak5Mm3ab6poGm2aZlpsdMu8zoZv5mIrMys+NmLxh6DBYjl1HBOMXoMTc2DzeXm282bzPvs7C1SLIosthjcd+SYsm0zLQss2yx7LEysxpjNdOq1uqONdmaaS20XmN91vq9ja1Nis1Cmwab57YGthzbQtta23t2NLsAuyl21XbX7In2TPsc+/X2lx1QBw8HoUOVwyVH1NHTUeS43rF9BGGE9wjxiOoRN52oTiynAqdap4fO+s5RzkXODc6vRlqNTBu5YuTZkV9dPFxyXba63B2lMypiVNGoplFvXB1cea5VrtfcaG6hbnPcGt1euzu6C9w3uN/yoHuM8Vjo0eLxxdPLU+pZ59nlZeWV7rXO6yZTlxnLXMI8503wDvKe433E+6OPp0++z36fP32dfHN8d/o+H207WjB66+jHfhZ+XL/Nfh3+DP90/03+HQHmAdyA6oBHgZaB/MBtgc9Y9qxs1i7WqyCXIGnQwaD3bB/2LHZzMBYcFlwS3BaiE5IUUhnyINQiNCu0NrQnzCNsRlhzOCE8MnxF+E2OCYfHqeH0RHhFzIo4FUmNTIisjHwU5RAljWoag46JGLNqzL1o62hxdEMMiOHErIq5H2sbOyX2cBwxLjauKu5p/Kj4mfFnE+gJkxJ2JrxLDEpclng3yS5JntSSrJk8Prkm+X1KcMrKlI6xI8fOGnsx1ShVlNqYRkpLTtuW1jsuZNzqcZ3jPcYXj78xwXbCtAnnJxpNzJ14dJLmJO6kA+mE9JT0nemfuTHcam5vBidjXUYPj81bw3vJD+SX8bsEfoKVgmeZfpkrM59n+WWtyuoSBgjLhd0itqhS9Do7PHtj9vucmJztOf25Kbl78tTy0vMOiXXEOeJTk00nT5vcLnGUFEs6pvhMWT2lRxop3SZDZBNkjfm68Ke+VW4n/0n+sMC/oKrgw9TkqQemaU8TT2ud7jB98fRnhaGFv8zAZ/BmtMw0nzlv5sNZrFmbZyOzM2a3zLGcs2BO59ywuTvmUeblzPutyKVoZdFf81PmNy0wWTB3weOfwn6qLdYolhbfXOi7cOMifJFoUdtit8VrF38t4ZdcKHUpLS/9vIS35MLPo36u+Ll/aebStmWeyzYsJy4XL7+xImDFjpXaKwtXPl41ZlV9GaOspOyv1ZNWny93L9+4hrJGvqajIqqica3V2uVrP1cKK69XBVXtWWe8bvG69+v5669sCNxQt9FkY+nGT5tEm25tDttcX21TXb6FuKVgy9OtyVvP/sL8pWab0bbSbV+2i7d37IjfcarGq6Zmp/HOZbVorby2a9f4XZd3B+9urHOq27xHf0/pXrBXvvfFvvR9N/ZH7m85wDxQ96v1r+sO0g+W1CP10+t7GoQNHY2pje2HIg61NPk2HTzsfHj7EfMjVUf1ji47Rjm24Fj/8cLjvc2S5u4TWScet0xquXty7Mlrp+JOtZ2OPH3uTOiZk2dZZ4+f8zt35LzP+UMXmBcaLnperG/1aD34m8dvB9s82+oveV1qvOx9ual9dPuxKwFXTlwNvnrmGufaxevR19tvJN24dXP8zY5b/FvPb+fefn2n4E7f3bn3CPdK7mvdL39g/KD6d/vf93R4dhx9GPyw9VHCo7uPeY9fPpE9+dy54Cntafkzs2c1z12fH+kK7br8YtyLzpeSl33dxX9o/7Huld2rX/8M/LO1Z2xP52vp6/43S94avt3+l/tfLb2xvQ/e5b3re1/ywfDDjo/Mj2c/pXx61jf1M+lzxRf7L01fI7/e68/r75dwpdyBXwFFHYtmZgLwZjsAtFQA6LBuo4xT1oIDDVHWrwMI/CesrBcHmicAdfD/Pa4b/t3cBGDvVlh+QX5NWKvG0gBI9Aaom9tQVzVZppurkosK6xTCg/7+t7BmI60C4Mvy/v6+6v7+L1ugs7B2bBYra1BFI8KaYVPIl4y8DPBvmrI+/S7GH0eg8MAd/Dj+C1QLkM5xJxAgAAAAOGVYSWZNTQAqAAAACAABh2kABAAAAAEAAAAaAAAAAAACoAIABAAAAAEAAAGSoAMABAAAAAEAAAEUAAAAAKijy2MAADstSURBVHgB7d05rH1HVi5wt3kS6gQPaomOPGWtJ3kAkRC02w4QkScJIaTXniISPCVEeIpIPBIReIyQUHuSkEjak4RE5IkEEXhoEpL2lACJ/X72115d3me45/7v2fd/zrlrB+fWXrVq1apv7/rOqrVrn/uDr7/++oI+GoFGoBHYHwQu3B9X29NGoBFoBL5BoGmr74NGoBHYMwSatvbsgrW7jUAj0LTV90Aj0AjsGQJNW3t2wdrdRqARaNrqe6ARaAT2DIGmrT27YO1uI9AING31PdAINAJ7hkDT1p5dsHa3EWgEmrb6HmgEGoE9Q6Bpa88uWLvbCDQCTVt9DzQCjcCeIdC0tWcXrN1tBBqBpq2+BxqBRmDPEGja2rML1u42Ao1A01bfA41AI7BnCDRt7dkFa3cbgUagaavvgUagEdgzBP7Pnvnb7m4JgVU/xv2DH/xAlc+xH5I333yzhNdcc83FF19cp6PmCcurvIrZSY/vvffe559/rooz1157bXVNeNFFFy1tUjpd2G8E3Ch9nDUEHn/88dy1l19++fXXXz+WSXJamLz77rt0Io++Uwe1W2655aOPPirNExaYStc+2Q/1+Py2t984+dxzz1Uv5Ag0Td55552S04m3aVvyLhwMAhcczEh6IJsjYLZjLvpfffWVz0zyav7666+b8HWawu23344gVJX8s88+oybMKcmqwobU9uCDD2KiDz/8MHbuuecePb700ks5TXejA+RqL7vsMmrcm/RuUJpMhH16GAg0bR3GdTzGKPACdqgGTk37UYLLxtNoJq6pVilQ03aMdCYKOf3pT38aflxaGyGFq6++eiSa9Pjpp59WK92Np+So7Ze//CX25MZY9cYbbywSWdnpwr4j0Cl5N/zZOl555ZU77rijxixppRwCivD9999P/FU62IRw1FHl1pddUrjiiitK85wLTAncZKliIT1irksuuaRsSlqNp+RvvfXWDTfccO+99ypbG5Ym2vrZz35Wp104MASatg7sgh49HDP/rrvuKr3Q1jjJcceoQHOR2gjR3xdffCGomVBJWa7CJJVe8rHAyP3331+SpT3ed999paCA2rjK+J133un07/7u7zBpFJDsOKII+/NwENj3cLH9PwkClmbJDa1fxCXNVItBynJMgizx17isW+UJtfX2FxtOEluLCiQSW9JhqUrqrRJh1pvH7XFpFy3cTQR6A8ThfAOdw0g+/vjjX/3qV2hlfUBkLcb4Aw884NN9/Mknn1hF/s3f/M3dd999Dp1u0iQ9ro+YRGQeZcaagOvFF198+umnb731Vo8+rTfXj2gTH1pnZxFo2trZS3Maji1di006rsSWCEvVkXSACsetDJpYS6ajsszIGkpamtiqtlVAbU8++WROZbgwqV503YmtguhQC01bh3plNxpX2MScX6Nd1HYkYcWIxPmEpNDQRCIntYa2orxGQUdsJrFVnj/00EOiv0ceeQRvjun5UujCwSDQtHUwl/JcBpK12OQR4cTQJiQyNrFAc4wSvTz88MMbsp6GG3o1cdvyUFL/1Vdf/b3f+72tPNwch9DlnUKgnyTu1OU4VWesp2SpbKpaTyiIgFvrY5/t+r0JUdKZuCT4srFDrEe+fkTb9batnT4CHW2dPubnv8fwQoKaq666SkGifcICvJQk+vLLL1Gb6ImOEGbWKEYqXRYM79i+oKMPPviAD7Zu4aMRMju8HBLwl156qW0TY2Rnh4Ss/OJAxuZdPgAEvnlv9rjDeP7550XjkgvHbdj6u4CAOW9613UXmCj7DJeVh1GrUwWxzGQ/11i7poxHMOCREdBIN3FPE6vLUa6X8VSZwti1oTlmpdexuy6fFwSOTVu+DK+88kqf9sUceSOelyF1p7uGAHLZhLZ2ze32Z2cROHZuy/ManLWz42nHdhAB4Xl/w+3gddlfl45HW5K49W6aRcT+Drs9P00Eesl2mmifhb6OR1tSG0888UTesz1uzFXJlLMAa4+xEWgE5kPgGLT18ssvI6zrrrtu1ZenJ0H2znjfwjHu9xOj4bubvz2SQEV5JNSQYI1NuTY9W1Z4QsSarYPS/17dkGctTc1JNJckFvQ99dRTVaWgVi9q6eSJOCF/ZFgYLLbV0OnYsMuNQCOwHwgIgjY5JOA9is5PGnl/1djyO3PV9tlnn/WzR/kVN/kvCnmXFdl5gK3WabjMG7nYxGfslAXN82asZ5QojpwRbWk+9thjytK6hH4fijCaqsg1LCPa4jv2uYouMSxNXvnMD0vFQ/p0sHA1rILXcfm//jCc0u9CI9AInDICm+7bEr+Y5/mJkkRbFbYgDtzkvQqTOa+JiJVwnCysiEZU5W1+n9T81Amm+J3f+R3kImrzHoZTcgdKsmcne3CoiZW0Jdc2mgymlillbdWqYsHpNya+PYRUHOOAM5+CNa0os8lJwtoERIIcv230vQ8287NzJV1MJx/5Uy3VtguNQCOwdQQ2oi1hi118fowNeaFVvxkw8cM6zlS3KIscWaRAH4mUHFOQk1jW+bT9Or9PQphNQ0hH2SdyiXLxHblDvGbfY/0Uuo5shsyvxKXWEwPs+a3uBbxyKGMiBnWH48J92dmY7qJcn0g5vFySYxX+6q/+6p/+6Z+O1aSVzzICvumfeeaZs4zAOYx9I9qSVxJqIax0YLmngD5yigJwhx88WoxKMIUXx+zzGj3DII4sGIvRWBM0jdEcIsMyEwZJCCYWq64Vin1WvYbCiPguLBknR5YcfUu5RrpYFcniSEvzL//yLztlVmh04UgEfvSjHx2p0woTBI6mrWwUrGS59oIvr1aUIXGT8oRfSDL5E92UchUQkABNHBRNtJXIy8oOl2mLWSbvytIUTGlVfYV9dCE0w2U8UTthyfQ44TvdLXJiNEWIxciRLH56jy+r1MWq//vtsShvSSPQCGwLgSNoCxFIWmGusb+whlRUhCEmAdSoI0DDdEjEMcpFbSY8C8k6paqiJOknsRvayuqvwqiykK4T7PDttddeC7XJoKMtTCTuK2UFnpNUTJdoTkPEJLG1NGjKQng0slhe2nBRrSWNQCMwCwLimqWHkErOKDShUDoyR5VLQhZ4QZXndDQ913NY/aESBETuqRzaEgp5ikdy00031TO4X/ziF6o816NDX1nGCvXQ1DD5KT4ojwf7UEgr1pKnp8wBap4esoMuNRSIoUjcZHmoillVHNZWL4yUJ6P9LjcCjcDuI7DynUTxjsAnMZSlWW2bsogT1Jj2xkYuoZhoC39lyYa/kkcPyzKS5Do5vhifwSEyazdd0NedU+FVnkWSM5iEeuzUZwxqJYYS9djtpVyaSKrWsxTGBaMuklBj6tFHH0VtIeWyvN0CfNYbHEM2vjnoazXKEfp4ut7ghrXrHRu7E5Zmcc0yrBzVhWtNM976PliVCij9YxVcmqCxtJXLndyC2m9QOy3c0h3flnpFODoW6ILPInRlYVJV8i4cgQBkD/5wq2FMkVpGKkYTqc09apMZ9PpCPT6VSZQd4f085YgbokX5slyq6DhNKxHiFl3Nv4rgQHqJkymXk9Wdbw5V8RYxlVxBGFttE+qOtScsC+f1O0GjPFEo+760JppOIxmXCKV/woIInfEauGvkIAl0Psu+L0hV0RxvNl+rJdew/mdHNezCJgh88/V+8Id5ZQ7kFrEUdTMhsllHrS83cRa8OnLKgXEiuZUns90Kl45beXQsbxFMNEeFKm8yIo+Ajb023OaJMFYqI8CZOKCKxMG34v3o49NNHKNsrm7iXrmhALpFNMjR5aTTjGKkDGoid8095BltLi0L3pfKVwnTHRgnCryC0iik6b8ihfTrToiCO6FzFCNWxy0f4+Ue98GeHnYkuK0taa1GrW7cqeN6Z45BWRdbq9YSNY8mM/nTneDFMXadJfaoo5bbPo98sumq12OH0eakzCtqWYarSo/jcw8uTZBh2XpHYEi/Vt8xa/2YLOGkl8VTgNfyfLF2qWQpGjQDyNhkcRRqE+a44qPmYtnoKvuxWLtUku6w56QWjBPfrF7dAHk+PoGOkQ2hm/TSp0HgTNCW2ehGwQiiCU8ti03muwlMmJEOFqeW55sTgljU4V5SS/nGPrm3aMv3fNlJjyNRYqhJX8EN2ZHb9SJuquZ8mzBvVZ28MEFDX8lhsTwC63RxFIRRDnmd3JnRwsQxHeUa0ZHbmmjC1jclN0CHIlObwpjkHVt1eSMEgNjH1hHIA9aYzerPV/HYi+hjPFXOd7WVxSh337vpJ6uzUSFlrWguyicSS6dREsLiXgmFRZPVnLVPFtcK7qdaoHFpTNmUhaUFy9JquFRhIjScsGehISUXx3yizlF/cRRqI9wWbovd1aLPuILP4kKYz1mPJ59Yq0LCTVavY6ddniBwJnJbkzGf8mkSW+vv1FCbZG18M11NAzEOzsqsWO/zhrQ1GtEEDR3535u5FF5LskmEGCPiVsdocE35uLSVvoRyeTxthYXFltrPKOorIbhJusGtaGJpwwiPi1u6E1XFMU/VlUfeH/viM32SGk5qi+lG5S4fC4EjtptuFLC10loEJsuKpbrR8bJnEk8Wa66ikEH4M9OStrwadzxMfOODTcVZznBDhuuFF14QJyZFaF/uRH9bp/ENcacLq7BET4v2o2nFXbhpJfE0E27pDidmT7J+cdPS5Z6oEO0GW9Bh/7fffhvZ8VOm8rgJtcWBn3FJ09bsN0ARxJqeoiN+SaZ2DZXEiCeM9ZZCJKbQhEeYWpN72tCrkS9CW9I0wkA5nTXGxTvjECgfy734hh9DRqxN0kaFZOHGpbHHUpgUNsFN7mySPisj6U5+MPsE0VD2JJZCFWiiqjrlHtoSnbHsO2kp05VyF45EoGnrSIhOpODL3z/OsopZf6fmWaF7epO5xyGUIRQaPTN/xnmiatVUT6v0GF4Y7Yxlc49LJaFsIIRyZBxY46pWo3vCE0Ym7k2eSFQvCoVGhKBb9dytNNc4M1rmmCsyShZx29wxXLzqtXkojSEV2vJOG8aH2/hNMHrS5WMg4PbqYz4ENk9sVYLmHJw5bo4mU1ePSb6s6tEEmyRuJIzcWwhxk8xRmT1WbiuZIF1X81WFZJpWpb1WtRrlx8KtulsPWuwvYiulFeg2SVaOTnZ5EYEzsQHiGCy+bVXfukyOMctiD5voLLY6icTqRnPUsCZIsZZZXM6IGoRO5OtHdBLfgsYmIcnmmifxp9pWd2tAi7LEFpQmagm+ZoWuXD34QtPWLJfYjesutwDxGxU68L+dndYGn+pS0ofc2oHEXa5cVXMUzBmrKr340Uf249Vip9R4Lu9uEaTgtJzhpAyXAGfNSqqUj1sIGkHswgsv5BjJUiPRzCiiOTq5tMlJhIvdSfkvNRjobrvtNthOoLPUBZ0obH26YKnZFk4QWPkq9USvT4+FgOQr5po0kRuaBCkTNaQwSatPLKw6FUUzvkhAE30KibMi152GZtGYhVGFXvNyTNTw10hSmcPCrtRu8qlTXa/6hbKyMEGDfBGxKGOEkTgMxBDW5/Kql7Fwbrix4F3upem2CcKL0HF7VTpsdKzL6xFo2lqPz37Ubjj9ztdgMpmPpK3Td2/HcTt9QPalx6atfblSR/hpeXIO4cYRRrdXvbPu7axj28P+AC01bR3gRe0hNQKHjUCn5A/7+vboGoEDRKBp6wAvag+pEThsBJq2Dvv69ugagQNEoGnrAC9qD6kROGwEmrYO+/r26BqBA0SgaesAL2oPqRE4bASatg77+vboGoEDRKBp6wAvag+pEThsBJq2Dvv69ugagQNEoGnrAC9qD6kROGwEmrYO+/r26BqBA0SgaesAL2oPqRE4bASatg77+vboGoEDRKBp6wAvag+pEThsBJq2Dvv69ugagQNEoGnrAC9qD6kROGwEmrYO+/r26BqBA0SgaesAL2oPqRE4bASatg77+vboGoEDRKBp6wAvag+pEThsBJq2Dvv69ugagQNEoGnrAC9qD6kROGwEmrYO+/r26BqBA0Tg/xzgmA59SM8999wnn3yyZpQ/+/aIAuWPP/7Yv5uf6F977bVL/x38RK1PG4EdRKBpawcvyjqXPvvss7vvvvuaa665+eab6eGvF154oU79j+Wnn37a/4hHXLGCnvy36ttuu+3yyy9HYRG+9957d955p6pXXnlll/+Xdbztz0ZggkDT1gSQXT9FNDfddNOrr74aR5944gmFO+644/777y/Xr7jiiipfd911uMwpmrvhhhsiV7jkkkvuuusuRDY2rFZdaAR2GYHObe3y1VniG8J68sknq+LNN99Urtgq8pG2SN59912fYqvU5lNEpmD9OAq73AjsBQJNW3txmX7jZOKmK6+8spx+6623LrroIiFVSd5///2KqiJ8++23FSbUpiHhhMvKSBcagV1G4Af51t1lF9u3VQgIo/7gD/5gXDMuarq+1oPiL/msqhVkYToZsQRrJe9CI7AXCHRuay8u03Inl64QJ6rY6osvvhCgUfY8EYuRPPLII7fffrvPiXKfNgJ7gUDT1l5cpuVObkJbb7zxhsYWkikoe3T4zjvvjCvN5dZb2gjsKgK9SNzVK3OUX1n90bIlYnFbVrW2OUsW/8MPP2yeKky6sO8IdEp+X69gVn8S7Ws4C7WJyOzYas7a18vcfi9DoGlrGSr7IMsK8frrr1/jbFHbGp2uagT2DoGmrb27ZL9xODsYJtsaJoOxN5Vkvc6kSZ82AruPwKa5LcuNPIcypDWrkt0f8L57+NBDD2Uf1piPv/feeycvGNqSirPs4bLVy+YsafhKye87Au1/I7ARbbnvTYARLNOA0G4gL5coj1XbKttbZOLdd999mxg0OZ9//nnv2c3kzCY+nI6OdZ8cfPrKd4my1NVkZ3zUKKj1NePomCug9echIODO3uTId7Vv9VL2EF2uF018+umnJdxiIVkbj8A2sfnggw+6GC+99NImyq3TCDQCe43Aprmt0NaYALbN2hu8whwx0Rz8/fDDD7/++usbPgLzVvCzzz576623zuFJ22wEGoGdQmDT7aZLE8Drf/XphOM81qLGEglznbDHbt4INAJ7gcBGuS3x5IUXXugVNhmTGhWhl92cEmIN4ZiXSCSGxV8kk/d7oyaLLEYbQ7ZYS1tLzrwSzAJNNqXPqrsUPvroIwSqaiS1l19+mSejJMrxBLf+9Kc/rajNe3wkSWCzJmdX/U766tNGoBHYTQQ2WiQu3SKU6MYPNiERxGErtvS5ZRpGQA1qCTNmpzjFsy3EJ4U/ZtnpaM4+mtPWKa7xy1B513dkSab0RYcmeTGahSrqkYzPL08Vyk7p6Pqrr77Chqll/6mnnuIAfY/klOmzKWdXDSeFTVIAkyZ92gg0AvMisMm0TMIbH5nqyiY5rvHDA7LyaS6Awg4+cQqhNBOnH3/8cbVOpe1TdipdRS2tokbiVDZdE8Ydv/zlL8VBTvFUNH3KzZN4iKaMqnSkR23pkzglVMhxzz33kFQ6Px2xma7zu6DPPPNMlDXk4XdNp381EaxNDsLxEC1Om/V5I9AIzIbARrmtJLZ+/vOfm955mo6/skJEJY4s0ARBqE1oo0p0I6JRlfhIgGMIkvePPvoooiFHIg888ADKyI9DaUXulzYFZTfeeCP7dMIvCg7xl095el2wpiFPLPcS1lmfljIS8cPEiLIWhkhWWz2Wn5T9tDGhg2VhYMqLn4k0F+WbSP77v//7H//xHzfRPBidP/mTP/nxj398MMPpgewmAkfnttCNxNZll11memOKVcOwHPPbT+KaLB6jFqHkkQN3OHBZ2ASvoS2rNjS0aJOmJd74jNLikRA9UVaV1WUaojBL1HqjGCW99tprTpFsFJAguhSaoUjkddVVVyG1/BgxtUsvvVR0lgXjoicnkdgagrVPYmHv2gL2D//wD/fO7XZ4vxA4OtpKuGHCr+EsY45awpmCANcoY42Ry1KLaBQstUq5CsIlYVSyUSXEQRgHkQn9/NMH68f8XJQukFSCL8pINln24ixCfVkzJh02eSQaZlx0r/rlTJVXFRAxSl2sRYjpbrGqJY1AI3DOCGxKW0v5ZezV/BRS1bpsrJoIRW0mOWU640rTaaqwEpYRhWEuXIMxrQpFQ2I3/OKgVvbxDuaioFbZKhJhjZxFjsisQNMXGioKYwSj8UQvuBXnZsVaxhWsfNkfJYvlySgWFVrSCDQC20RgfdZM2jt5H5HOek1cIOSZ6GiOFJI1V2VFhh2iZslmGGVWFZ5KDh5FWrWRKMSgQpXl+PVV6XYGeUjN2jBC3aHFNPz1r3+NkvySZ0598mf006knDPqKkVLrQiPQCOwsAt+sqlYdiCB8kc/xzZ5JE9MeBwlkJnKngh3NUZJYxvO48f0beRCsQe7ALPVckhyJaKVtDCqQRBPplKZanTLCVWm16h3rEbKg1SinwE95sdIM6419VVUXGoFGYDcRODolv5XQzuDZWcyOkRPm88iOVhlZ2nBz5Q17X9rLhkKr2jxXXdTP8PPsNQkyyhbCNMuxFNTadLL1HL9VsCX2omMlqWepNPMcoxyLjm8I3yWL6+uy0IVGYMsIuAX7mBuBRH/iPktjhxjQVbQiVhYtChWdWlCXG9bOiIBQMCiStfilZvFLgv5KbSsF9rkh3mRcMjEu+XTEsbEXnkRIk8NxjJPaVipg1O9yIzAHAusWiXP0dwZtJj9ohtfY5eYcdZoMYJ2mILDCBWMr8pDLkT+5sWY5P+mlTkVMuhupU5XeMWzppBDOnWguFU4a9mkjsC0ENnq5xw3dxzkjYG1lVtfjVHk6u89CQGUzy8M6dXU9mbVXbiLPI9Qjn2zqkYWydmRBcGfHiczjZBWv9/GZLDtCM49lOT/RJFR7pGNHetIKjcAmCDRtbYLSiXRM6aSEYmVxgxuFyZ5bvIPaPIIY2SHkIiwqBjyRW0PjiUuVicNli45pN+FcRBxhbwQZQO3ijAgcvW9rxs7PhulJMn7CETCwRcMxgrGoI3rCfZaWHoOOmlspT7qTdAsxibYm2fqJpt7LMa224kwbaQSORKBp60iItqxg9Yd98hM9q0xnb/2vfvUrNCHysvjKRn9xzdZDLT6kO28deAVKX3qU1VrqWzQ/+OADYWAcszdYADiTY0t9aGEj0LR1qveAqW71l3T7qo7FL9gKF0h7e4BIDcd5sLiGsBYzWRPJuNic9Ju1p/BKX+FHbxos7YtNtMUxzwTKMen/XhtOIO3TuRFo2pob4e/Zz2yXtPqe9PsnoTb7DPLS5fcrl5z53x+TBZpk2WQXFRqitqTxdy+Toi3UhoAUVrmX9zc3d2xpdy1sBE6OQNPWyTE8hoUsslbxQgxtQm1jl3Jnk/QZ+4ysibDG5klXFc1hLtHWqFDlxcRWVXWhEThNBJq2ThPtC8z8IxNb+TeIxSNz+zdh0m/fQ794aafRPDXHlvrQwkYAAr0B4pRuA4mhrP7Wh1q8yY9STHZszeSlvQ52OeS54foupL2sPW1Am+zkWt+qaxuBORBo2poD1e/ZRA0iFGl1hwqsJNNEgghGvaglvY1KKEwyVqPyycs4VBdxSRilMNmiVV1EM0n6ZM1mdaz67UIjsAqBU3qVelX3Z0e++aO9k2NyrNyW7uLbhrmwk7vXFhqBEyLQua0TArhp89MkBRn6Y3V3LOVNB9x6jcBsCHS0NRu0bbgRaATmQaBzW/Pg2lYbgUZgNgSatmaDtg03Ao3APAg0bc2Da1ttBBqB2RBo2poN2jbcCDQC8yDQtDUPrm21EWgEZkOgaWs2aNtwI9AIzINA09Y8uLbVRqARmA2Bpq3ZoG3DjUAjMA8CTVvz4NpWG4FGYDYEmrZmg7YNNwKNwDwING3Ng2tbbQQagdkQaNqaDdo23Ag0AvMg0LQ1D65ttRFoBGZDoGlrNmjbcCPQCMyDQNPWPLi21UagEZgNgaat2aBtw41AIzAPAk1b8+DaVhuBRmA2BJq2ZoO2DTcCjcA8CDRtzYNrW20EGoHZEGjamg3aNtwINALzINC0NQ+ubbURaARmQ6BpazZo23Aj0AjMg0DT1jy4ttVGoBGYDYGmrdmgbcONQCMwDwL9X6nnwfU7q0888cQXX3zx3dmSv/7xvSMVzz333CeffDJR8i+jr7/++tKZ1PZpI3AGEehoa8aL/tFHHz3wwANvvvnm119//dVXX3388cePPPJITkk+++wzp++++255cMUVV5ATPv/886gqx6effnrLLbfccMMNpdaFRuCsI2Ce9DETAo899tiDDz5YxpXdbS+99FJJENPrr79epwpq6YytCB966CHCxx9/fNTsciNwZhHoReKM31uvvvrqK6+8Uh289dZbypPlngirFBTEYj4nOu5Ows8//9xnH41AI9CLxLnuASvEK6+88pJLLqkO0NY111wzSi6++GI6paCwlNref/99Vddee+2o2eVG4Mwi0LQ116XHR1JUZf2NN95QtiosicIYizmV7cJQdKThS03yS9R200033XrrrSXsQiNwlhHoReIpXf2lq79J39HBdwqYy9rwvffek6G/5557nnrqqYlynzYCZxaBpq1TuvRLV3+TvkNb2CqhmVqZr3feeWeykJy06tNG4Kwh8M1X+lkb8+mPF8gXXnihxJboaU3vslcWiXY8jPmvNfpd1QicTQQ6t3Ua1z05rElia9JxEluTnP1Ep08bgUYAAk1bp3EbbJ7YWk9tp+Fr99EI7DwCTVuncYk2SWxFp3fDn8b16D72HIFNc1tJgY0P5k9/4Hw4vw4cd8h2t7/99ttajdHWvffe62Wd0dSTTz5pi4O0lw2l0lvS8C+//PKo0OVGoBEYEdiIthbJwjbuiy666I477phvM5GtmHkJWdJH2dy+//77ua7TcT/UOJhdK2Mizser4tzrrrvOcEZXSy068vG9s3TEp8uNwBQBU2WTwy8ZaOknCqLsaZdX5EjEDps0PzcdiR4p6mqbbQH9al4B0oVG4GwisGlua1zmYCsRQWKfWbdBSveMKWqvy+h68r4eSR+NQCNwphDYiLYwuoXM5ZdfLu1S6IzLnxJusZDYaiQp1GllapG1xV7aVCPQCOwdAhvtkvdDUX6+7vbbbx+HlwSTReKY+cJlQiSpZVHSZG+3WMleSmkdiZsxueOdO/qUR07UEaL0WbSFOifB1+hMlxuBRuDsILBRtJUVYj2bxzLWhn4Az89CyZQXWB6c0ZH2QjEKyC5V9O+777677roLqSGjCpfIPVPzzp3CnXfeSe6zrOl03HsZ6iwWK7UqbLLIL+UuNAKNwP4isFG0JcwxQjyCdHzmVwo+/PDDMZ7ygI+a0CkvptgXLrxKAIVrcIpWjOApBJQfdck+AAbJtcJ0fudA2ZHYis2c+ozaKtpSm9/SK/0xBowwNkuhC41AI7CnCBxNW2Y7UpDY8hgxXOCpolALhRVtyUO9+OKLzz77rNUfSnrhhRcsKtEQULAJwvI+cADCRA4NWUNz+TFPVcmUFSsxbvdDnVKID6t2BtAMt6aX437+27/92/jjyMdtvr/6f/RHf/STn/xkf/1vz88mAkfTViW2Kn6xVwttyW3Vpq3kubCVAgYRZOEdgKI8y0mUVwvDamJ1Kb+egIsmVvIZplOY5OMTKMmXlQ90tngg1meeeWaLBvfF1A9/+MOmrX25WO1nIXA0bYVQxsBHPFXtUxBb4aBojlUoT9B08803j0JlNPTBBx+MNCRWGvc62Fx+rMRWFp6TXhZPixYnVf/v22Mi7NNGoBHYTQSOpi3vnXB9pK3Q07hew1njKX1ZdkeeGE4eEaIY8ddok6Z4R4JfQVbeqy26sJakIxyTJqserU9Zq5CNQg4NF0nzu8rf/OXMKtqaaPZpI9AI7DICR9BWNjSY8BPqMaSs1/L0ENfcdtttxVPyRDajWgZqJYYSWAUCQRYOsmz0SZ58llbZuYpTEFZCMzGaJL38V0IwTMeClabHjuPTxpj1iTQnvFlVXWgEGoEDQ2DdO4kVYaEbJIUvQhnyVoIgtEIB9SSxJQ6S25JrJxFM4SwKwMJK9nYJplKFleyEwIOMsEYoUqOAy+hYGMaaDROoDev5pIy29MWgnyfW/MCuQQ+nEWgEjoXAOtpab0jWHKFUrp0ydvO5NGu+pmpVL+HKsXZRMtZupSx4XPVE0rg4gD0ffvjh9IVhMbVyRqeQsSNfRIyRo7atzzW+6UKw6asiffGwRmHpXUtj62jhavnj7c7x8pW8C43AriNgyvURBPzjaKGfeNC2DP91Nb8eI3JE0E4J8ZHaES4bOzRxWBdr7pQmHYSuPGqevBzj7qdySV98s++EA+LQ6iKe5M6zFa7kCppojsu27t7YS5cbgVkR+CZS6CMIIKaRlbKnTNxU+JjtjjpVsOcWO0jAjUJUsigcFVJGLqPxRYVFCdJh2cOKSdWiY1jJy1iXXXYZfU9+S1+naMtnSbrQCOwdAhu93OPWPwuHPJqFWI00jybzTKCEk8R/tqdNdNwEpb++kObrdcbapS5FYbLcQ53Ws1KEavOjQ1HTo5hx6UJ+7KjLjcAuI9C09durI+U/Tv6kh0z+0pCummSswiO1aTaa6E+hXlSq5icvTFxCsnGAV5NHvTa+8dxDD+tHLzB4MJLe6Y8jOrlLbaEROA8I7F18eDoOeyHcxRCYrO+OAl4YdSwbJbaObKiJldpkdTnaWSzT55J1X5Z4ntiiqkW1WL766qujlt/tkP+KplVwZ7WWgtbCPUKgo63lXxVrlmPVAHHYtCFG80iRvud3FmUe28mOH3f1VzbXFOLSl19+eeONN+pFhCVLtVRf78LGrATz3NP+EpruS1WTde5SCy1sBHYZgSO2m+6y67P6NlmOLe0rPCL8kfN20BHLSCStyhxhjUU7E+GqthqmO7sW7FzDPvhITLdokERiq9Jt2E3ZcAgTBq7pYqm1FjYCu4ZA09byKxKOWJ8Gig76qI1Ry219J0U3YbfvBBcI1iZdeGFgkikr5dElERPOWtWvxNaYhve8Em3ZYqbJpLsy3oVGYJ8Q2KMF7am5ukliS+ZI/siVPmevWNg8t0VZX1aF1Z2dYlUeC3HM5yjMchJtdWJrhKXLe4pA57aWfMeMcc2S6m9FfvQiP2KxSmG78sVF66oU1ZjYKh/yXrp3pFa1Ks0uNAK7j0DT1pJrtMgREyXfUVJFhKez5tq8O5pe35HDmjicl9UFd53YmiDTp3uJwJ5GiXO47Qcn0NC4Acrp4kb2+l0K1xtB0JGxOgd/Nlwk2pw1pt51x4Gl3Y17ZRf3Rgi4ahvE0uYtbAT2BYFzf5V6L0l6A6dduWitD0w2VFvTIQty6lmQrlFTVX1t4lj01zu/vruubQR2HIF+kji9QBtO+A3VptaHcxby8s0gW148bl/H1V/ea0sbgV1FoKOtXb0y7Vcj0AisQKBT8iuAaXEj0AjsKgJNW7t6ZdqvRqARWIFA09YKYFrcCDQCu4pA09auXpn2qxFoBFYg0LS1ApgWNwKNwK4i0LS1q1em/WoEGoEVCDRtrQCmxY1AI7CrCDRt7eqVab8agUZgBQJNWyuAaXEj0AjsKgJNW7t6ZdqvRqARWIFA09YKYFrcCDQCu4pA09auXpn2qxFoBFYg0LS1ApgWNwKNwK4i0LS1q1em/WoEGoEVCDRtrQCmxY1AI7CrCDRt7eqVab8agUZgBQJNWyuAaXEj0AjsKgJNW7t6ZdqvRqARWIFA09YKYFrcCDQCu4pA09auXpn2qxFoBFYg0LS1ApgWNwKNwK4i0LS1q1em/WoEGoEVCDRtrQCmxY1AI7CrCDRt7eqVab8agUZgBQL9X6lXALN74q+//np06uOPP7744osvueSSUdjlCUoFyKz/qfvzzz9/77339HXFt4fCm2++6fOiiy667rrrFPrYLgIdbW0TT7fvww8//LOf/eyWW2558sknt2n6ggvuv//+G2644cJvD5PhrrvuuvXWW6+99lrMpdPt9hVrN998s4Gst2y68uq5555br3Y6tXHmyiuvBBJYOOYA0VVXXQUiV2cmN5DUfffdp6/gwA3dOXXJZurxrJv17dTHVhD47LPPrr/++pdeeunDDz98/PHH3VgmzFYsj0Z0wfIoef3110nuvPPOUXjy8ldffZW5obDGWkZ60003rdE55aoA8tBDD6Vf/r/zzjsCH5fDNZrPGXA9+OCDZd+VctRpF7aIQEdbmZtb+PRNayXiq97ha9Yd7Fv3iSee2ILptSZ8q5sezz///LvvvrtW8XiVxmK2o4D1yytBH6Z+6qmnjmf9FLX5LzhF6y7HjkSFpzj6w+yqaWtr1/X999+3WHjllVdi0VJR4dVXX13agcyUWbS0qiwsrY3QF9dibfIpi/JzlpjtOHF9c/k1a1UpnfVq51a7CgrQAfBYNvlJf+sQHcuHVt4WAp2S3xaSF8humBtHJoPSH03f/znKA8kXNHHvvfeWZMNCsjYhyuS5Lr/8cqaEYAhFL7HzxhtvvPDCC5988sk111xDLTM5VaJCtMsOI/RVCUxoqrXaSsBlzmNhlKE5ieUhBV3QGXtx+vLLL7/11lusWZeBhcRBM1zDvkIYRJy4hhmt6fiDvEZXOSa4O5KAJsxu7HzQ9TeufHd89NFHTBm4EYFdmPxdzW+GoIqHWhmgKm5LWULAaYAq/Ul3Je/CLAhsccHZpkYELBJdsMcee2wUjmVz0mwxCSN0apI/++yzo85i2Sxidsw3WaOR3H777VHWrzyOeSWhHgY0Y1WxTK6sozvuuEPXCuQ+2XRIyTmY0jD6dKovDVHhp59+qirJIz6Y9hmm5uQ5GHfQZBm1VUccYJlBLKCVvtJW4bumS/5qVRZUg2s8XdLgO/cY56GDt5hXv5wZ9cmxoU9CysqGEwVg6sWQNTdq1yVyAGIrZT5TMMzIfdLURSXUSL7BdIClNLtwcgS+l9w9ubm2EATMWNPAnb0eEGpXX321mamwCWexZiaYHj7NH4dW5hULY0fRkZmS7brnnnsYN834g8XKvZrGFJTDHTRZI4laaMWEdKpcs9epLiJP2amCIxl6dnLqEwjhQWVEoK9xtjtluZSXFoq5qrBUrYSYiFkD+em3h4KxTyCiTD4+SXCagWcIoTNq/HfEuEKNlEG9ALn6nYyFZimXThe2gkAvEt1s2z8EFJdddtmRCxnTyWIK+zz66KNmr/T2hq74VteK8pp8eXYMJVkuSLFkE4KFODTUNfes4Cwbzcasjwitg9QuHtpaHLGJg/DXqqGxhitEJWWBvtEhMjsS3LLkukttTktzVSGw6DQ++1ylOcqR4yOPPBIJH+6++25DqAUpHKxwnRYg3LMkpJ90ZOB1atRlNmVjofnll1+Sf/HFF1XbhVNDoFPy24fahDFv3dkbTjDUs+EELl81yVGS9YUkv8Yvul/84hfJgpl4m/iJOxCrZRQukIMPJ046Zd+oJ445pZYJn/LSthNT2z1Nfi1puFgO7Y6AWM7nsS9XARJXJ27gOEzHfwVt1eZzotancyPQtLVlhMU1LAo6fLqnKyG9tJukwK1NTBVhUdou1ZwIjztbQkzCjRuH41j0IQqzq4PDlkVxON5OPLHUojMKMR3ndT0ZwuanOgIOiCxyBUGh4M2bl+YHH3xQ5QRTvB3wuDGAcHUyhLRCVZQ1AQXuPm7MWF134eQING2dHMPfWjDBfI3jLPPWIfTIpP2txlAyN3x14zWBDFrRcHPmWhoLDLanRc83BYDjfgK9i7bYsYCyULXwqTZWuFWugqF5PujU3OanrE2Wk6Mnyjoy6pFZnNYitKxtXghnAQdEgDo35oqTiM9F0bWCUSCgt99+e/Qk3zGGRqjHqgKUwQa9POVQVctDF7E0J4V0NxH26RYQ+GZ69bENBJIJnlySVflmNCFZY06OPROa4Z4MjsIqC3PMpYQtHsNnnVK1VSBnmRuUx4RxUsg+pdJ1hJuSdZaMx2ia5CkhhWSm1Ya/2EG+smm6VtCR5soUFHSnrDm1VBmChnpxsMZ43PB8IC88YQFlpsKDlFeNBRSs6aVGp8Am4SipcvzJ4heBMhuHDY0bMAm2aa5MWI8XLe1TywiFAoTzmF0XSdVbSCrTCbu5ggp60Rf76VQtNFiADLnT8rALW0Hg6KyKb0432WQ2jqdrvm1GtYMv+65eBMpqopK7IwK+vR2LVdB2x7v7R+WU2a94IeGDKTEGO9TcE7kcCk7FFOOrkfSdJpnFWvVuXlkAcl5a2iRMJju17OgCs9DRkAOiHk6a5DJcTkUfFKIWf9TqJSxm3iKR5Pvjf5zkGGrIUjqjWxwLuQCHG3qMTn0yzrKjJCnwRy+jkJ/J6BudgiFgEw8QS2iwWhFmRGlrCOhJEGpcehFdxgckFZ8JjcswmWXBpRwTZ+RxI1dBc/ZHr7p8QgSOpi23iFvK1fLkxaUVWqdLd4BL5TPXxqfL//TTT/vm0eSEbnXzRmAOBHKvTrh+jo7a5qwIHE1bunexfWGiLWH/eMnRk+9hXzVWEMl3vPbaa76um7ZmvWZtvBE44whslJJHTDgLH42cBTgBfIIvcbJFxJjxPeOw9vAbgUZgPgQ2oq1ET2grflj5h6HQWdIW5BNGm8/jc7Oc1cG5te1WjUAjsFMIbLRLPrSVHC3vPQDCXAoSk7KP5zwedqTMkuKVJqvMa3K6MmUk6KYSojqSE33xxRcJJY898Er6WfqTh9LYnvgknayQnKsmuJXw17/+tW3NcrEPPPDAOTvcDRuBRmAXEDg6t1WJLQksHicT7+G3h0GTAdD0q5Ib5rZwlqdX4SaM47lSGAdnISNv6iEyW348rvJeq6rIrUkxF85Cl5p7eI+wVJHgKV0zqwnHQrWUqRGGc8WGeV428ZyaVfBEODnVdVHhpKpPG4FG4DQRODraSmLLpMVKPMtGmJM/0BVDiYmymwZ5eUaZYeMXQVYeM3uCKWUWxkFtyiQJyjx3x0ehNp95LQP7YFXWPChgjbI30Wy3SVBmIIQIzufkMJwk6Uq+uOat5XDpdKERaATOCwJH01bCFrSSaAgX4K/FWb3U+//8z//8l3/5l6rydvEf//Ef5xRh2S3hySNWqggI+4iw7CeMDmJyKAuXbKLx1lg4iyQcpCDsIlQrXguzCL7SPAtYYZQtNrgM67GTqsnnYuQ4UVh/KgrjwHqdrj3LCPjifOaZZ84yAtsd+9G0lQmZkEffopVQySZ+/Ou//utf/MVflOaf//mfF20hQdznbXuxEmYUxFHLy/eLmy3jQ4KmWAuZIiz5NTRKod66iAIhTsRlrClb4a6nWjrl59LCmuaSaz//+c+XtmphIwCBH/3oR43DFhE4mrZCEEVbx1oe/tmf/ZmtXovuiqpERnkcKRRCYUKhLN8s1hbXcWIlRsauEZx4LYvBeFgPOsfu0FZ5PsonZT4cGS6xT23SMKd6WSpvYSPQCMyBwBG0JQhaumNrc1cWgxTLTI/zJNoTVSWvVJwlOTUaTwJeFmykFRbQlrVkWoW2xliMBf1qVQvG2MxSV4A2dqGMj04SbU2s9Wkj0AjMisDvrIogJI/khuw2+Pd//3fs8F//9V8obFUOKMrep8cgeOd///d/McuER2oYCEWchbn+53/+xyqSA//wD//w4x//mAIK+9u//dsf/vCHTiW5VOEda9Kf/OQn//zP//wf//Ef5Aok4rV6ridYs1rMW2DVi8Lv//7v//3f/72w7nd/93ex3l//9V//6Z/+6RqvOLbmGC13uRFoBM4jAis3QGCi5JsShpjPwq4syhbdXVRGN9mIsKhMwrKUlgK6EXMllR5Nq8Wk0idVDIq8fE7kWjGF7xyxMH5WRyIs/mg71p7fcsV3sFWuz/Pr1a71PkEp7sFqbj/1667WUcXm7kxTYOltNrczbX+KgMvTx+kjIOU3ZsTk6ZKbCynnJ2W265VZ5xuifqdllXFPdfNsd5XCacrzuzd1y9YmFcv/OSCqoWU/jX7zu0MwiQ+uUel04Twi8M1r0n2cLwTqeUU54Jeh7P43SczYEm6lYJ4zix/XW0vvq34mbH3bmWo5w3PPgmMfaPnpK5nKmXpkNkuNEQc+NG3NB/ixLG/0TqIL1sfpICCNmDWy3J8LucVOJfXMdgvt9TblDc3Vzfe4rLe2pjYUsEZhVZWFG/fEqvYkS6GuUjuhvCK7E9rp5nMg0LQ1B6onspnEjSxenpCeyNb3G5vtaxKO0ZXKySOO7zfd/tkJ81NJU24dou2Psy3OgMARGyBm6LFNLkFAYFXTuIIsDIK87FmTG1b2/Z+fM6ussIVM3oIikbca7XofwKNYkqoSmOTNp3p2LGWT/b2Mq7JfV0cOPWo17ncrTUmleppMKEWtF8u3eMIONzZ87lHDHN1eU57o85Py5LkwN4wIaDyZPD6qIYxVBSBTlpzjo6GJJ5PeJ7V9etoIuB59nC8EKrelUD54h8lNIMdEYl5hCqfowLyysFImVJV0NXryY+dWTGZpLEi9Y5wkrenQTxqeQYktp+lLQ628i17ZNHLUlu7GnI4ddg69ODiA3dKRvHVWUhae9LVVixQ4EIX1n5THUa9RZpzbcUkTPiNKEv2OrZzyx7goGBrmrVqDIvFT8Q4NMwQwYlhuQCBgjvlEHdGshBpTTimXzS6cRwQ6JX8ewf/Nf2DP9DBDTCeMY+5NnveZLXQyu/KPlDEISU2zzEZCg6GAnigrR604KHZCFspFQDQ1KRJhuZoo8IdCDpREs9wLfZRyMk0bPuPjQPX4nfnlf9nnEjc0yf+ORTeip1HbeAnD9eQoqfBJc1xG7pP/wVCZTuX1FVgom6GtGhq5hhwohS6cRwR6kejWPf+H2ZhFIiIweWrBWJ6ZMLL1dthmk23WhtTCFHlbwCZewY6FpGkZiQWde6uMjAWafoTD2pBlXGlhldpRX9k/lKZQDfkmivEOfHL2Ua6VWk4Xndfcmi5UUqZ0PclMMV4r0FKrAlqRdHPKjh7hYOyaRMHevawNA0iEOuVSfi48C0CfmDceKuMmZTrWxQoFQnU6FqqvUdjl84JA09Z5gX3aqXmYuTStWHFumqkxgR1RERdgn8gxy4p2vxV7XmlWm+0OUs1DCr/V+O5fSY+SlEMHqxwOeU1aCY4coxB9jBSjCo+soa1qSw2F4VOrwnriGcYx/KIeI4KDU/xYbRVGt/EmCuaYNXiQ5PyoMJYl8nD9aKrL5wuBpq3zhfz3+h2nx/cqVpxYMakx2SbzPNRQU3dF62/EqMekNVd9it2wwKK1zNKlNLTG8tKxeII5eYjpVTBEuVR5jfGxygtbRVuRS/BV6BfJGudlwW677TYMCArK4tzxvdfF5sE88v48vwj0Bojzi/859o5itExsFRPmnkUiFpOCsU4c7SaeGiXKXuHUROSS1ZZWi2RnpSmTPYlWdCrDHbqZkE5O1zDFxIdzPs0SuBw2kDw3zG+KxKxaA+eSRa7HnYK76i6AWDySCNkirxEJWkkmQyMRbUWzP887Ak1b5+0SmN7FCCbVmtluBpZm3BW5eLonRMrShgIaQjFqzUPT2GcMet7nlLzs14SsUIVxR2KrcIHTdFTWcpq3XurdlyinymdOcURJTl7gdpxhvIaQdJvgKGSEs/CvJwze/M9TCP06TXzEWw0NNs0FpKH71MZbdkJ59U0Q0AqrGmn5cPKhtYVzRmDlq9TnbLEbboKAu99ypuZApof12qStWYSPSmhFIziqU+sak+3SSy9lR66qUlpyRtZfJh4iI1ROd9WQst1bJr9dTroWarGMCpFUIhSaGlJTMM9ZwI/U9IUFcAQ5xzLJGc9ateZ8ta0eFwuCGn4WLywqkPAnDx+qtobJDV5lScj5hJ+E9MViXOJehNpmCODlGEw0lF/HRKgNAglRAaIJ0EBKf+yX2aJ41o50u7ztwkwING3NBOwpmTU/V818VZxYVXtc/7ZrTe+b0NaRTmKQ9c8fRwtLh7AGwLFtl3cKgaatnbocZ8gZoZnY5wwNuIe6PQSatraHZVtqBBqBU0GgU/KnAnN30gg0AttDoGlre1i2pUagETgVBJq2TgXm7qQRaAS2h0DT1vawbEuNQCNwKgg0bZ0KzN1JI9AIbA+Bpq3tYdmWGoFG4FQQaNo6FZi7k0agEdgeAk1b28OyLTUCjcCpINC0dSowdyeNQCOwPQSatraHZVtqBBqBU0GgaetUYO5OGoFGYHsING1tD8u21Ag0AqeCQNPWqcDcnTQCjcD2EGja2h6WbakRaAROBYGmrVOBuTtpBBqB7SHQtLU9LNtSI9AInAoC/x8UWmvx8s/x0QAAAABJRU5ErkJggg==)"],"metadata":{"id":"J--X0AqreiQY"}},{"cell_type":"markdown","metadata":{"id":"XxKmOcdH7XWG"},"source":["### Определяем критерии оценки\n","\n","Как типичная проблема классификации, критерии оценки классификации настроений могут обрабатываться так же, как и обычные задачи классификации. В качестве эталона можно использовать общую точность (Accuracy), точность (Precision), скорость отзыва (Recall) и показатель F_beta.\n","\n","$Точность = количество правильно классифицированных образцов/общее количество образцов$\n","\n","$Precision = количество истинно положительных образцов / количество положительных образцов для всех предсказанных классов $\n","\n","$ Recall = количество истинно положительных образцов / количество положительных образцов для всех истинных классов $\n","\n","Оценка $F1 = (2*Точность*Отзыв) / (Точность+Отзыв)$\n","\n","В наборе данных IMDB количество положительных и отрицательных выборок не сильно отличается, и точность можно просто использовать как меру классификатора.\n","\n","### Определить сеть\n","\n","Мы используем сеть SentimentNet, построенную на LSTM, для обработки естественного языка.\n","\n","> Сеть LSTM (долгосрочная кратковременная память) — это временная рекуррентная нейронная сеть, подходящая для обработки и прогнозирования важных событий с очень большими интервалами и задержками во временных рядах.\n","> Этот опыт предназначен для аппаратных платформ GPU или CPU."]},{"cell_type":"markdown","metadata":{"id":"9i18eZeX7XWG"},"source":["### 配置运行信息和SentimentNet网络参数"]},{"cell_type":"markdown","metadata":{"id":"0eL8eJxx7XWH"},"source":["1. Используйте модуль `parser`, чтобы передать необходимую информацию для запуска.\n","\n","     - `preprocess`: нужно ли предварительно обрабатывать набор данных, по умолчанию нет.\n","     - `aclimdb_path`: путь, по которому хранится набор данных.\n","     - `glove_path`: путь, по которому хранятся файлы GloVe.\n","     - `preprocess_path`: папка результатов предварительно обработанного набора данных.\n","     - `ckpt_path`: путь к файлу контрольной точки.\n","     - `pre_trained`: предварительно загрузить файлы CheckPoint.\n","     - `device_target`: указывает среду GPU или CPU.\n","\n","2. Перед обучением необходимо настроить необходимую информацию, в том числе информацию об окружении, режиме выполнения, серверной информации и информации об оборудовании.\n","\n","Запустите следующий код, чтобы настроить соответствующие параметры, необходимые для обучения (подробную информацию о настройке интерфейса см. в описании API-интерфейса `set_context` на официальном сайте MindSpore)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2971,"status":"ok","timestamp":1653914313828,"user":{"displayName":"Тимур Александрович Гарипов","userId":"06496796590508823817"},"user_tz":-420},"id":"UdD4HxEL7XWH","outputId":"f09713bd-5f70-4192-ed01-5d288ea11e2b","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Current context loaded:\n","    mode: 0\n","    device_target: CPU\n"]}],"source":["import argparse\n","from mindspore.context import set_context, get_context, GRAPH_MODE\n","from easydict import EasyDict as edict\n","\n","\n","# LSTM CONFIG\n","lstm_cfg = edict({\n","    'num_classes': 2,\n","    'learning_rate': 0.1,\n","    'momentum': 0.9,\n","    'num_epochs': 10,\n","    'batch_size': 64,\n","    'embed_size': 300,\n","    'num_hiddens': 100,\n","    'num_layers': 2,\n","    'bidirectional': True,\n","    'save_checkpoint_steps': 390,\n","    'keep_checkpoint_max': 10\n","})\n","\n","cfg = lstm_cfg\n","\n","parser = argparse.ArgumentParser(description='MindSpore LSTM Example')\n","parser.add_argument('--preprocess', type=str, default='false', choices=['true', 'false'],\n","                    help='whether to preprocess data.')\n","parser.add_argument('--aclimdb_path', type=str, default=\"./datasets/aclImdb\",\n","                    help='path where the dataset is stored.')\n","parser.add_argument('--glove_path', type=str, default=\"./datasets/glove\",\n","                    help='path where the GloVe is stored.')\n","parser.add_argument('--preprocess_path', type=str, default=\"./preprocess\",\n","                    help='path where the pre-process data is stored.')\n","parser.add_argument('--ckpt_path', type=str, default=\"./models/ckpt/nlp_application\",\n","                    help='the path to save the checkpoint file.')\n","parser.add_argument('--pre_trained', type=str, default=None,\n","                    help='the pretrained checkpoint file path.')\n","parser.add_argument('--device_target', type=str, default=\"GPU\", choices=['GPU', 'CPU'],\n","                    help='the target device to run, support \"GPU\", \"CPU\". Default: \"CPU\".')\n","args = parser.parse_args(['--device_target', 'CPU', '--preprocess', 'true'])\n","\n","set_context(\n","    mode=GRAPH_MODE,\n","    save_graphs=False,\n","    device_target=args.device_target)\n","\n","print(\"Current context loaded:\\n    mode: {}\\n    device_target: {}\".format(get_context(\"mode\"),\n","                                                                            get_context(\"device_target\")))"]},{"cell_type":"markdown","metadata":{"id":"Q_PJNxpE7XWH"},"source":["### Обработка данных\n","\n","#### Предварительная обработка набора данных\n","\n","Выполните предварительную обработку набора данных:\n","\n","- Определите класс `ImdbParser` для анализа текстовых наборов данных, включая кодирование, токенизацию, выравнивание, обработку необработанных данных GloVe и обеспечение их адаптации к сетевой структуре.\n","- Определите функцию `convert_to_mindrecord` для преобразования формата набора данных в формат MindRecord, удобный для чтения MindSpore. `weight.txt` в функции `_convert_to_mindrecord` представляет собой файл информации о параметрах веса, автоматически сгенерированный после предварительной обработки данных.\n","- Вызовите функцию `convert_to_mindrecord`, чтобы выполнить предварительную обработку набора данных."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":160686,"status":"ok","timestamp":1653914474510,"user":{"displayName":"Тимур Александрович Гарипов","userId":"06496796590508823817"},"user_tz":-420},"id":"vMfLI2X57XWH","outputId":"d4e1a4ae-46f1-4af2-8441-aa7904b57b03"},"outputs":[{"name":"stdout","output_type":"stream","text":["============== Starting Data Pre-processing ==============\n","======================= Successful =======================\n"]}],"source":["import os\n","from itertools import chain\n","import numpy as np\n","import gensim\n","from mindspore.mindrecord import FileWriter\n","\n","\n","class ImdbParser():\n","    \"\"\"\n","    parse aclImdb data to features and labels.\n","    sentence->tokenized->encoded->padding->features\n","    \"\"\"\n","\n","    def __init__(self, imdb_path, glove_path, embed_size=300):\n","        self.__segs = ['train', 'test']\n","        self.__label_dic = {'pos': 1, 'neg': 0}\n","        self.__imdb_path = imdb_path\n","        self.__glove_dim = embed_size\n","        self.__glove_file = os.path.join(glove_path, 'glove.6B.' + str(self.__glove_dim) + 'd.txt')\n","\n","        # properties\n","        self.__imdb_datas = {}\n","        self.__features = {}\n","        self.__labels = {}\n","        self.__vacab = {}\n","        self.__word2idx = {}\n","        self.__weight_np = {}\n","        self.__wvmodel = None\n","\n","    def parse(self):\n","        \"\"\"\n","        parse imdb data to memory\n","        \"\"\"\n","        self.__wvmodel = gensim.models.KeyedVectors.load_word2vec_format(self.__glove_file)\n","\n","        for seg in self.__segs:\n","            self.__parse_imdb_datas(seg)\n","            self.__parse_features_and_labels(seg)\n","            self.__gen_weight_np(seg)\n","\n","    def __parse_imdb_datas(self, seg):\n","        \"\"\"\n","        load data from txt\n","        \"\"\"\n","        data_lists = []\n","        for label_name, label_id in self.__label_dic.items():\n","            sentence_dir = os.path.join(self.__imdb_path, seg, label_name)\n","            for file in os.listdir(sentence_dir):\n","                with open(os.path.join(sentence_dir, file), mode='r', encoding='utf8') as f:\n","                    sentence = f.read().replace('\\n', '')\n","                    data_lists.append([sentence, label_id])\n","        self.__imdb_datas[seg] = data_lists\n","\n","    def __parse_features_and_labels(self, seg):\n","        \"\"\"\n","        parse features and labels\n","        \"\"\"\n","        features = []\n","        labels = []\n","        for sentence, label in self.__imdb_datas[seg]:\n","            features.append(sentence)\n","            labels.append(label)\n","\n","        self.__features[seg] = features\n","        self.__labels[seg] = labels\n","\n","        # update feature to tokenized\n","        self.__updata_features_to_tokenized(seg)\n","        # parse vacab\n","        self.__parse_vacab(seg)\n","        # encode feature\n","        self.__encode_features(seg)\n","        # padding feature\n","        self.__padding_features(seg)\n","\n","    def __updata_features_to_tokenized(self, seg):\n","        tokenized_features = []\n","        for sentence in self.__features[seg]:\n","            tokenized_sentence = [word.lower() for word in sentence.split(\" \")]\n","            tokenized_features.append(tokenized_sentence)\n","        self.__features[seg] = tokenized_features\n","\n","    def __parse_vacab(self, seg):\n","        # vocab\n","        tokenized_features = self.__features[seg]\n","        vocab = set(chain(*tokenized_features))\n","        self.__vacab[seg] = vocab\n","\n","        # word_to_idx: {'hello': 1, 'world':111, ... '<unk>': 0}\n","        word_to_idx = {word: i + 1 for i, word in enumerate(vocab)}\n","        word_to_idx['<unk>'] = 0\n","        self.__word2idx[seg] = word_to_idx\n","\n","    def __encode_features(self, seg):\n","        \"\"\" encode word to index \"\"\"\n","        word_to_idx = self.__word2idx['train']\n","        encoded_features = []\n","        for tokenized_sentence in self.__features[seg]:\n","            encoded_sentence = []\n","            for word in tokenized_sentence:\n","                encoded_sentence.append(word_to_idx.get(word, 0))\n","            encoded_features.append(encoded_sentence)\n","        self.__features[seg] = encoded_features\n","\n","    def __padding_features(self, seg, maxlen=500, pad=0):\n","        \"\"\" pad all features to the same length \"\"\"\n","        padded_features = []\n","        for feature in self.__features[seg]:\n","            if len(feature) >= maxlen:\n","                padded_feature = feature[:maxlen]\n","            else:\n","                padded_feature = feature\n","                while len(padded_feature) < maxlen:\n","                    padded_feature.append(pad)\n","            padded_features.append(padded_feature)\n","        self.__features[seg] = padded_features\n","\n","    def __gen_weight_np(self, seg):\n","        \"\"\"\n","        generate weight by gensim\n","        \"\"\"\n","        weight_np = np.zeros((len(self.__word2idx[seg]), self.__glove_dim), dtype=np.float32)\n","        for word, idx in self.__word2idx[seg].items():\n","            if word not in self.__wvmodel:\n","                continue\n","            word_vector = self.__wvmodel.get_vector(word)\n","            weight_np[idx, :] = word_vector\n","\n","        self.__weight_np[seg] = weight_np\n","\n","    def get_datas(self, seg):\n","        \"\"\"\n","        return features, labels, and weight\n","        \"\"\"\n","        features = np.array(self.__features[seg]).astype(np.int32)\n","        labels = np.array(self.__labels[seg]).astype(np.int32)\n","        weight = np.array(self.__weight_np[seg])\n","        return features, labels, weight\n","\n","\n","\n","def _convert_to_mindrecord(data_home, features, labels, weight_np=None, training=True):\n","    \"\"\"\n","    convert imdb dataset to mindrecoed dataset\n","    \"\"\"\n","    if weight_np is not None:\n","        np.savetxt(os.path.join(data_home, 'weight.txt'), weight_np)\n","\n","    # write mindrecord\n","    schema_json = {\"id\": {\"type\": \"int32\"},\n","                   \"label\": {\"type\": \"int32\"},\n","                   \"feature\": {\"type\": \"int32\", \"shape\": [-1]}}\n","\n","    data_dir = os.path.join(data_home, \"aclImdb_train.mindrecord\")\n","    if not training:\n","        data_dir = os.path.join(data_home, \"aclImdb_test.mindrecord\")\n","\n","    def get_imdb_data(features, labels):\n","        data_list = []\n","        for i, (label, feature) in enumerate(zip(labels, features)):\n","            data_json = {\"id\": i,\n","                         \"label\": int(label),\n","                         \"feature\": feature.reshape(-1)}\n","            data_list.append(data_json)\n","        return data_list\n","\n","    writer = FileWriter(data_dir, shard_num=4)\n","    data = get_imdb_data(features, labels)\n","    writer.add_schema(schema_json, \"nlp_schema\")\n","    writer.add_index([\"id\", \"label\"])\n","    writer.write_raw_data(data)\n","    writer.commit()\n","\n","\n","def convert_to_mindrecord(embed_size, aclimdb_path, preprocess_path, glove_path):\n","    \"\"\"\n","    convert imdb dataset to mindrecoed dataset\n","    \"\"\"\n","    parser = ImdbParser(aclimdb_path, glove_path, embed_size)\n","    parser.parse()\n","\n","    if not os.path.exists(preprocess_path):\n","        print(f\"preprocess path {preprocess_path} is not exist\")\n","        os.makedirs(preprocess_path)\n","\n","    train_features, train_labels, train_weight_np = parser.get_datas('train')\n","    _convert_to_mindrecord(preprocess_path, train_features, train_labels, train_weight_np)\n","\n","    test_features, test_labels, _ = parser.get_datas('test')\n","    _convert_to_mindrecord(preprocess_path, test_features, test_labels, training=False)\n","\n","if args.preprocess == \"true\":\n","    os.system(\"rm -f ./preprocess/aclImdb* weight*\")\n","    print(\"============== Starting Data Pre-processing ==============\")\n","    convert_to_mindrecord(cfg.embed_size, args.aclimdb_path, args.preprocess_path, args.glove_path)\n","    print(\"======================= Successful =======================\")"]},{"cell_type":"markdown","metadata":{"id":"9vvvkeFV7XWH"},"source":["После успешного преобразования в каталоге `preprocess` будет сгенерирован файл MindRecord. Обычно, когда набор данных остается неизменным, эту операцию не нужно выполнять при каждом обучении. Вы можете пропустить ее, установив `--preprocess false ` при выполнении сценария. Просмотрите структуру каталогов файлов `preprocess`.\n","\n","```text\n","preprocess\n","├── aclImdb_test.mindrecord0\n","├── aclImdb_test.mindrecord0.db\n","├── aclImdb_test.mindrecord1\n","├── aclImdb_test.mindrecord1.db\n","├── aclImdb_test.mindrecord2\n","├── aclImdb_test.mindrecord2.db\n","├── aclImdb_test.mindrecord3\n","├── aclImdb_test.mindrecord3.db\n","├── aclImdb_train.mindrecord0\n","├── aclImdb_train.mindrecord0.db\n","├── aclImdb_train.mindrecord1\n","├── aclImdb_train.mindrecord1.db\n","├── aclImdb_train.mindrecord2\n","├── aclImdb_train.mindrecord2.db\n","├── aclImdb_train.mindrecord3\n","├── aclImdb_train.mindrecord3.db\n","└── weight.txt\n","```"]},{"cell_type":"markdown","metadata":{"id":"4pQ3ovJV7XWI"},"source":["На данный момент файлы в каталоге `preprocess`:\n","\n","- Набор обучающих данных в преобразованном формате MindRecord, имя которого содержит `aclImdb_train.mindrecord`.\n","- Тестовые наборы данных в преобразованном формате MindRecord, имена которых содержат `aclImdb_test.mindrecord`.\n","- `weight.txt` - это файл информации о параметрах веса, автоматически сгенерированный после предварительной обработки."]},{"cell_type":"markdown","metadata":{"id":"Qn8y0UzF7XWI"},"source":["Создайте тренировочный набор:\n","\n","- Определите функцию `lstm_create_dataset`, чтобы создать набор данных для создания обучающего набора `ds_train`.\n","- Создайте итератор словаря с помощью метода create_dict_iterator для чтения данных в созданном наборе данных ds_train.\n","\n","Запустите следующий фрагмент кода, чтобы создать набор данных и прочитать список данных «метки» в 1-м «пакете» и «функции» данных для 1-го элемента в 1-м «пакете»."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1168,"status":"ok","timestamp":1653914475670,"user":{"displayName":"Тимур Александрович Гарипов","userId":"06496796590508823817"},"user_tz":-420},"id":"aX8Kfftt7XWI","outputId":"f67c546b-3b33-417d-baac-cca2c217f733"},"outputs":[{"name":"stdout","output_type":"stream","text":["The first batch contains label below:\n","[0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0 0 1 0 1\n"," 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0]\n","\n","The feature of the first item in the first batch is below vector:\n","[ 73704  73939 103536  55305  17626  51536  28128 162089 174306  58034\n","  53953 137565 150655 165358  84324 184172 118746  48494  14313 216022\n"," 199538  55305 170389    499 152521 240281 108431 120182 214350 165936\n","  22858 224272 251744 152419 176785 160751 178521  97009  73704  34941\n"," 224272  21016 120182  70421 197257 109794 107502 120182 181952  53953\n","  96562  87495 197257 102107 248292  35706 233878 152466 130392  55305\n","   1682  68522 115665 122583  37404  56835 224272  53813 130055 175969\n"," 131414 197257 135904 100427 137092 130392 237481 183601 197257 168631\n"," 224272 184246  43442 138424    499 183495 115665 205713  53458 173547\n"," 147093 112168 152466 193381  69067  22316  10467 214350    499  84278\n","  35034  33900  35323 244876  55305 173995  52746 224272  85946  61362\n"," 113156  19557  35323 214350    499 233321  35034 125400  73939 169521\n"," 176785     64 197257  99246 231796  33900 112168 152466  92356 162411\n"," 181952 153891 100120 181952    499 153758 154308 162119 197257 135904\n","  11347  15220 190234   8184 115665 219071   5353 138294  24548 246423\n"," 161291  43982 147427 169521 176785  99532 114069 138294 130055 129356\n","  28128  43399  14313  14376 150070 200037 116919  60446  33900 181952\n","    499 194992  91247 120182  43442   7275    499  99421 121145 176785\n","  76891   9393      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0]\n"]}],"source":["import os\n","import mindspore.dataset as ds\n","\n","\n","def lstm_create_dataset(data_home, batch_size, repeat_num=1, training=True):\n","    \"\"\"Data operations.\"\"\"\n","    ds.config.set_seed(1)\n","    data_dir = os.path.join(data_home, \"aclImdb_train.mindrecord0\")\n","    if not training:\n","        data_dir = os.path.join(data_home, \"aclImdb_test.mindrecord0\")\n","\n","    data_set = ds.MindDataset(data_dir, columns_list=[\"feature\", \"label\"], num_parallel_workers=2)\n","\n","    # apply map operations on images\n","    data_set = data_set.shuffle(buffer_size=data_set.get_dataset_size())\n","    data_set = data_set.batch(batch_size=batch_size, drop_remainder=True)\n","    data_set = data_set.repeat(count=repeat_num)\n","\n","    return data_set\n","\n","ds_train = lstm_create_dataset(args.preprocess_path, cfg.batch_size)\n","\n","iterator = next(ds_train.create_dict_iterator())\n","first_batch_label = iterator[\"label\"].asnumpy()\n","first_batch_first_feature = iterator[\"feature\"].asnumpy()[0]"]},{"cell_type":"markdown","metadata":{"id":"Tpf58Xna7XWI"},"source":["## Определим сеть\n","\n","1. Импортируйте модули, необходимые для инициализации сети.\n","2. Определите тип устройства, для которого требуется стекирование одноуровневых небольших операторов LSTM.\n","3. Определите функцию `lstm_default_state` для инициализации сетевых параметров и состояния сети.\n","4. Определите функцию `stack_lstm_default_state` для инициализации параметров сети инициализации и состояния сети, требуемых стеком небольших операторов.\n","5. Для сценариев CPU настройте стек одноуровневых малых операторов LSTM, чтобы реализовать функцию большого многоуровневого оператора LSTM.\n","6. Используя метод `Cell`, определите структуру сети (сеть `SentimentNet`).\n","7. Создайте экземпляр `SentimentNet`, создайте сеть и, наконец, выведите параметры, загруженные в сеть."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":62085,"status":"ok","timestamp":1653914537752,"user":{"displayName":"Тимур Александрович Гарипов","userId":"06496796590508823817"},"user_tz":-420},"id":"t-CQ3JuE7XWI","outputId":"02086b5c-c8af-4d2b-8b91-aab4c69efcfd"},"outputs":[{"name":"stdout","output_type":"stream","text":["OrderedDict([('embedding.embedding_table', Parameter (name=embedding.embedding_table, shape=(252193, 300), dtype=Float32, requires_grad=False)), ('encoder.weight0', Parameter (name=encoder.weight0, shape=(320800, 1, 1), dtype=Float32, requires_grad=True)), ('encoder.weight1', Parameter (name=encoder.weight1, shape=(240800, 1, 1), dtype=Float32, requires_grad=True)), ('decoder.weight', Parameter (name=decoder.weight, shape=(2, 400), dtype=Float32, requires_grad=True)), ('decoder.bias', Parameter (name=decoder.bias, shape=(2,), dtype=Float32, requires_grad=True))])\n"]}],"source":["import math\n","import numpy as np\n","from mindspore import Tensor, nn, Parameter, ParameterTuple\n","from mindspore.context import get_context\n","from mindspore.common.initializer import initializer\n","import mindspore.ops as ops\n","\n","STACK_LSTM_DEVICE = [\"CPU\"]\n","\n","# Initialize short-term memory (h) and long-term memory (c) to 0\n","def lstm_default_state(batch_size, hidden_size, num_layers, bidirectional):\n","    \"\"\"init default input.\"\"\"\n","    num_directions = 2 if bidirectional else 1\n","    h = Tensor(np.zeros((num_layers * num_directions, batch_size, hidden_size)).astype(np.float32))\n","    c = Tensor(np.zeros((num_layers * num_directions, batch_size, hidden_size)).astype(np.float32))\n","    return h, c\n","\n","def stack_lstm_default_state(batch_size, hidden_size, num_layers, bidirectional):\n","    \"\"\"init default input.\"\"\"\n","    num_directions = 2 if bidirectional else 1\n","\n","    h_list = c_list = []\n","    for _ in range(num_layers):\n","        h_list.append(Tensor(np.zeros((num_directions, batch_size, hidden_size)).astype(np.float32)))\n","        c_list.append(Tensor(np.zeros((num_directions, batch_size, hidden_size)).astype(np.float32)))\n","    h, c = tuple(h_list), tuple(c_list)\n","    return h, c\n","\n","\n","class StackLSTM(nn.Cell):\n","    \"\"\"\n","    Stack multi-layers LSTM together.\n","    \"\"\"\n","\n","    def __init__(self,\n","                 input_size,\n","                 hidden_size,\n","                 num_layers=1,\n","                 has_bias=True,\n","                 batch_first=False,\n","                 dropout=0.0,\n","                 bidirectional=False):\n","        super(StackLSTM, self).__init__()\n","        self.num_layers = num_layers\n","        self.batch_first = batch_first\n","        self.transpose = ops.Transpose()\n","\n","        # direction number\n","        num_directions = 2 if bidirectional else 1\n","\n","        # input_size list\n","        input_size_list = [input_size]\n","        for i in range(num_layers - 1):\n","            input_size_list.append(hidden_size * num_directions)\n","\n","        # layers\n","        layers = []\n","        for i in range(num_layers):\n","            layers.append(nn.LSTMCell(input_size=input_size_list[i],\n","                                      hidden_size=hidden_size,\n","                                      has_bias=has_bias,\n","                                      batch_first=batch_first,\n","                                      bidirectional=bidirectional,\n","                                      dropout=dropout))\n","\n","        # weights\n","        weights = []\n","        for i in range(num_layers):\n","            # weight size\n","            weight_size = (input_size_list[i] + hidden_size) * num_directions * hidden_size * 4\n","            if has_bias:\n","                bias_size = num_directions * hidden_size * 4\n","                weight_size = weight_size + bias_size\n","\n","            # numpy weight\n","            stdv = 1 / math.sqrt(hidden_size)\n","            w_np = np.random.uniform(-stdv, stdv, (weight_size, 1, 1)).astype(np.float32)\n","\n","            # lstm weight\n","            weights.append(Parameter(initializer(Tensor(w_np), w_np.shape), name=\"weight\" + str(i)))\n","\n","        #\n","        self.lstms = layers\n","        self.weight = ParameterTuple(tuple(weights))\n","\n","    def construct(self, x, hx):\n","        \"\"\"construct\"\"\"\n","        if self.batch_first:\n","            x = self.transpose(x, (1, 0, 2))\n","        # stack lstm\n","        h, c = hx\n","        hn = cn = None\n","        for i in range(self.num_layers):\n","            x, hn, cn, _, _ = self.lstms[i](x, h[i], c[i], self.weight[i])\n","        if self.batch_first:\n","            x = self.transpose(x, (1, 0, 2))\n","        return x, (hn, cn)\n","\n","\n","class SentimentNet(nn.Cell):\n","    \"\"\"Sentiment network structure.\"\"\"\n","\n","    def __init__(self,\n","                 vocab_size,\n","                 embed_size,\n","                 num_hiddens,\n","                 num_layers,\n","                 bidirectional,\n","                 num_classes,\n","                 weight,\n","                 batch_size):\n","        super(SentimentNet, self).__init__()\n","        # Mapp words to vectors\n","        self.embedding = nn.Embedding(vocab_size,\n","                                      embed_size,\n","                                      embedding_table=weight)\n","        self.embedding.embedding_table.requires_grad = False\n","        self.trans = ops.Transpose()\n","        self.perm = (1, 0, 2)\n","\n","        if get_context(\"device_target\") in STACK_LSTM_DEVICE:\n","            # stack lstm by user\n","            self.encoder = StackLSTM(input_size=embed_size,\n","                                     hidden_size=num_hiddens,\n","                                     num_layers=num_layers,\n","                                     has_bias=True,\n","                                     bidirectional=bidirectional,\n","                                     dropout=0.0)\n","            self.h, self.c = stack_lstm_default_state(batch_size, num_hiddens, num_layers, bidirectional)\n","        else:\n","            # standard lstm\n","            self.encoder = nn.LSTM(input_size=embed_size,\n","                                   hidden_size=num_hiddens,\n","                                   num_layers=num_layers,\n","                                   has_bias=True,\n","                                   bidirectional=bidirectional,\n","                                   dropout=0.0)\n","            self.h, self.c = lstm_default_state(batch_size, num_hiddens, num_layers, bidirectional)\n","\n","        self.concat = ops.Concat(1)\n","        if bidirectional:\n","            self.decoder = nn.Dense(num_hiddens * 4, num_classes)\n","        else:\n","            self.decoder = nn.Dense(num_hiddens * 2, num_classes)\n","\n","    def construct(self, inputs):\n","        # input：(64,500,300)\n","        embeddings = self.embedding(inputs)\n","        embeddings = self.trans(embeddings, self.perm)\n","        output, _ = self.encoder(embeddings, (self.h, self.c))\n","        # states[i] size(64,200)  -> encoding.size(64,400)\n","        encoding = self.concat((output[0], output[499]))\n","        outputs = self.decoder(encoding)\n","        return outputs\n","\n","embedding_table = np.loadtxt(os.path.join(args.preprocess_path, \"weight.txt\")).astype(np.float32)\n","network = SentimentNet(vocab_size=embedding_table.shape[0],\n","                       embed_size=cfg.embed_size,\n","                       num_hiddens=cfg.num_hiddens,\n","                       num_layers=cfg.num_layers,\n","                       bidirectional=cfg.bidirectional,\n","                       num_classes=cfg.num_classes,\n","                       weight=Tensor(embedding_table),\n","                       batch_size=cfg.batch_size)\n","\n","print(network.parameters_dict(recurse=True))"]},{"cell_type":"markdown","metadata":{"id":"xvVf0S9R7XWI"},"source":["## Обучить и сохранить модель\n","\n","Запустите следующий код, чтобы создать оптимизатор и модель функции потерь, загрузите обучающий набор данных (`ds_train`) и настройте CheckPoint для генерации информации, а затем используйте интерфейс model.train для обучения модели. По выходным данным видно, что значение потерь постепенно уменьшается с обучением и, наконец, достигает примерно 0,262."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ppokYK927XWI","scrolled":true,"executionInfo":{"status":"ok","timestamp":1653923891753,"user_tz":-420,"elapsed":3711608,"user":{"displayName":"Тимур Александрович Гарипов","userId":"06496796590508823817"}},"outputId":"a885744c-7af7-4997-92f0-89a0c7b0a294"},"outputs":[{"output_type":"stream","name":"stdout","text":["============== Starting Training ==============\n","epoch: 1 step: 78, loss is 0.68990105\n","epoch: 1 step: 156, loss is 0.6607322\n","epoch: 1 step: 234, loss is 0.6768051\n","epoch: 1 step: 312, loss is 0.5804778\n","epoch: 1 step: 390, loss is 0.57390904\n","epoch time: 940850.415 ms, per step time: 2412.437 ms\n","epoch: 2 step: 78, loss is 0.6918031\n","epoch: 2 step: 156, loss is 0.6077039\n","epoch: 2 step: 234, loss is 0.6924745\n","epoch: 2 step: 312, loss is 0.63778096\n","epoch: 2 step: 390, loss is 0.6355504\n","epoch time: 949443.798 ms, per step time: 2434.471 ms\n","epoch: 3 step: 78, loss is 0.6125942\n","epoch: 3 step: 156, loss is 0.53423905\n","epoch: 3 step: 234, loss is 0.41319418\n","epoch: 3 step: 312, loss is 0.35350835\n","epoch: 3 step: 390, loss is 0.42095977\n","epoch time: 936889.035 ms, per step time: 2402.280 ms\n","epoch: 4 step: 78, loss is 0.46229306\n","epoch: 4 step: 156, loss is 0.40603283\n","epoch: 4 step: 234, loss is 0.38807216\n","epoch: 4 step: 312, loss is 0.41566047\n","epoch: 4 step: 390, loss is 0.365918\n","epoch time: 936843.687 ms, per step time: 2402.163 ms\n","epoch: 5 step: 78, loss is 0.35122654\n","epoch: 5 step: 156, loss is 0.49908772\n","epoch: 5 step: 234, loss is 0.3818769\n","epoch: 5 step: 312, loss is 0.30579183\n","epoch: 5 step: 390, loss is 0.5014232\n","epoch time: 931801.431 ms, per step time: 2389.234 ms\n","epoch: 6 step: 78, loss is 0.29254282\n","epoch: 6 step: 156, loss is 0.45277512\n","epoch: 6 step: 234, loss is 0.39386696\n","epoch: 6 step: 312, loss is 0.37410843\n","epoch: 6 step: 390, loss is 0.2576123\n","epoch time: 932917.436 ms, per step time: 2392.096 ms\n","epoch: 7 step: 78, loss is 0.32639816\n","epoch: 7 step: 156, loss is 0.4636322\n","epoch: 7 step: 234, loss is 0.18672396\n","epoch: 7 step: 312, loss is 0.27583265\n","epoch: 7 step: 390, loss is 0.33524495\n","epoch time: 932398.956 ms, per step time: 2390.767 ms\n","epoch: 8 step: 78, loss is 0.32418507\n","epoch: 8 step: 156, loss is 0.37186608\n","epoch: 8 step: 234, loss is 0.2886318\n","epoch: 8 step: 312, loss is 0.27101234\n","epoch: 8 step: 390, loss is 0.21682982\n","epoch time: 930897.060 ms, per step time: 2386.916 ms\n","epoch: 9 step: 78, loss is 0.37876302\n","epoch: 9 step: 156, loss is 0.2598502\n","epoch: 9 step: 234, loss is 0.53698593\n","epoch: 9 step: 312, loss is 0.28750786\n","epoch: 9 step: 390, loss is 0.17621078\n","epoch time: 930864.300 ms, per step time: 2386.832 ms\n","epoch: 10 step: 78, loss is 0.38778794\n","epoch: 10 step: 156, loss is 0.23484138\n","epoch: 10 step: 234, loss is 0.21173744\n","epoch: 10 step: 312, loss is 0.25913492\n","epoch: 10 step: 390, loss is 0.37420112\n","epoch time: 930856.045 ms, per step time: 2386.810 ms\n","============== Training Success ==============\n"]}],"source":["from mindspore import Model\n","from mindspore.train.callback import CheckpointConfig, ModelCheckpoint, TimeMonitor, LossMonitor\n","from mindspore.nn import Accuracy\n","from mindspore import nn\n","\n","os.system(\"rm -f {0}/*.ckpt {0}/*.meta\".format(args.ckpt_path))\n","loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n","opt = nn.Momentum(network.trainable_params(), cfg.learning_rate, cfg.momentum)\n","model = Model(network, loss, opt, {'acc': Accuracy()})\n","loss_cb = LossMonitor(per_print_times=78)\n","print(\"============== Starting Training ==============\")\n","config_ck = CheckpointConfig(save_checkpoint_steps=cfg.save_checkpoint_steps,\n","                             keep_checkpoint_max=cfg.keep_checkpoint_max)\n","ckpoint_cb = ModelCheckpoint(prefix=\"lstm\", directory=args.ckpt_path, config=config_ck)\n","time_cb = TimeMonitor(data_size=ds_train.get_dataset_size())\n","if args.device_target == \"CPU\":\n","    model.train(cfg.num_epochs, ds_train, callbacks=[time_cb, ckpoint_cb, loss_cb], dataset_sink_mode=False)\n","else:\n","    model.train(cfg.num_epochs, ds_train, callbacks=[time_cb, ckpoint_cb, loss_cb])\n","print(\"============== Training Success ==============\")"]},{"cell_type":"markdown","metadata":{"id":"NEwz_ZiH7XWI"},"source":["## Тестирование модели\n","\n","Создайте и загрузите набор данных проверки (`ds_eval`), загрузите файл CheckPoint, сохраненный **train**, выполните проверку и проверьте качество модели. Этот шаг занимает около 30 секунд."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"27J1J-sj7XWI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653924542266,"user_tz":-420,"elapsed":331245,"user":{"displayName":"Тимур Александрович Гарипов","userId":"06496796590508823817"}},"outputId":"cf451ac7-e6db-4ac5-8d4c-97466c7fbf35"},"outputs":[{"output_type":"stream","name":"stdout","text":["============== Starting Testing ==============\n","============== {'acc': 0.8496794871794872} ==============\n"]}],"source":["from mindspore import load_checkpoint, load_param_into_net\n","args.ckpt_path_saved = f'{args.ckpt_path}/lstm-{cfg.num_epochs}_390.ckpt'\n","print(\"============== Starting Testing ==============\")\n","ds_eval = lstm_create_dataset(args.preprocess_path, cfg.batch_size, training=False)\n","param_dict = load_checkpoint(args.ckpt_path_saved)\n","load_param_into_net(network, param_dict)\n","if args.device_target == \"CPU\":\n","    acc = model.eval(ds_eval, dataset_sink_mode=False)\n","else:\n","    acc = model.eval(ds_eval)\n","print(\"============== {} ==============\".format(acc))\n"]},{"cell_type":"markdown","metadata":{"id":"Umi8rlor7XWI"},"source":["### Оценка результатов обучения\n","\n","В соответствии с выводом приведенного выше кода видно, что после 10  эпох правильный уровень анализа тональности текста составляет около 85% с использованием проверенного набора данных, что в основном является удовлетворительным результатом."]}],"metadata":{"colab":{"name":"mindspore_nlp_application.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}